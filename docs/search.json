[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An Introduction to Network Analysis for GIS",
    "section": "",
    "text": "Welcome\nThis website hosts the materials for the workshop “An Introduction to Network Analysis for GIS”. The training workshop was designed by Dr Carmen Cabrera-Arnau, Prof Francisco Rowe, Dr Rafael Prieto Curiel, Andrew Renninger and Valentina Marin Maureira.\nThe website is free to use and is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International.\n\n\nContact\n\nDr Carmen Cabrera-Arnau, Lecturer in Geographic Data Science\nc.cabrera-arnau [at] liverpool.ac.uk\nDepartment of Geography & Planning, University of Liverpool, UK"
  },
  {
    "objectID": "overview.html#description",
    "href": "overview.html#description",
    "title": "Overview",
    "section": "Description",
    "text": "Description\nThis website hosts the materials for the workshop “An Introduction to Network Analysis for GIS”. This training workshop was designed and is delivered by Dr. Carmen Cabrera-Arnau, Prof. Francisco Rowe, Dr. Rafael Prieto Curiel, Andrew Renninger and Valentina Marin Maureira\nThe website is free to use and is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International.\nContact\nDr. Carmen Cabrera-Arnau, Lecturer in Geographic Data Science\nc.cabrera-arnau [at] liverpool.ac.uk\nDepartment of Geography and Planning, University of Liverpool, Liverpool, United Kingdom"
  },
  {
    "objectID": "overview.html#structure",
    "href": "overview.html#structure",
    "title": "1  Be prepared",
    "section": "1.1 Structure",
    "text": "1.1 Structure\n\n\n\n\n\n\n\nTime\nActivity\n\n\n\n\n15 min\nWelcome, introduction to workshop activities\n\n\n20 min\nDownloading the workshop materials from Github\n\n\n35 min\nImporting libraries, network theory basics\n\n\n10 min\nComfort break\n\n\n45 min\nThe African road network\n\n\n45 min\nExperiments and percolation\n\n\n10 min\nWrap-up"
  },
  {
    "objectID": "overview.html#before-the-workshop",
    "href": "overview.html#before-the-workshop",
    "title": "1  Come prepared",
    "section": "1.2 Before the workshop",
    "text": "1.2 Before the workshop\n\n\n\n\n\n\nImportant\n\n\n\nPlease make sure you download and install the most recent version of R, RStudio and Quarto on the computer that you will be using during the workshop, and install the indicated R packages – see detailed instructions below.\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll three software packages are open and free to use.\n\n\nR\nYou can download R here. Make sure you select the appropriate version for your Operating System: Windows, MacOS (Apple silicon M1/M2 or older intel Macs). For example, if you use a macOS laptop with an M1 processor, click on ‘Download R for macOS’ and then, click the link to download the installer file (.pkg extension for macOS) under the header ‘For Apple silicon (M1/M2) Macs’. You can then open the installer and follow the instructions that you will be prompted with. For Windows users, click on ‘install R for the first time’ and follow the prompts.\nRStudio\nYou will also need to download RStudio Desktop (or simply RStudio), which is an integrated development environment to help you write code in R more easily. To download RStudio, follow this link and scroll down to the section titled ‘All Installers and Tarballs’. Download the appropriate installer file according to your Operating System. Then, open the installer and follow the installation instructions that you will be prompted with.\nQuarto\nDownload Quarto from this website. Quarto is a publishing system that will allow you to open and work on the computational notebooks for the workshop. On ‘Step 1’ on the website, download the version of Quarto that matches your Operating System. Open the installer file, run it and follow the prompts.\nR packages\nOnce you have installed R, you will need to install some R extensions, known as packages, that will be useful for the applications explored in this workshop. The packages you need to install are:\n\ntidyverse\nggthemes\n…\n\nTo install the packages, open RStudio. On the console window (normally at the bottom left), write the following command: install.packages(\"name of package\"). Make sure you replace “name of package” by the actual name of the package that you want to install e.g. install.packages(\"tidyverse\"). Then, press enter and repeat this process until you have installed all the packages in the list.\nYou can also install all the packages by copying and running the code below:\n\nlist.of.packages.cran &lt;- c(\n   \"tidyverse\",\n   \"ggthemes\"\n)\n\nnew.packages.cran &lt;- list.of.packages.cran[!(list.of.packages.cran %in% installed.packages()[,\"Package\"])]\nif(length(new.packages.cran)) install.packages(new.packages.cran)\n\nfor(i in 1:length(list.of.packages.cran)) {\n  library(list.of.packages.cran[i], character.only = T)\n}\n\nYou can load all the packages by copying and running the code below:\n\ndeps &lt;- list(\n   \"tidyverse\",\n   \"ggthemes\"\n)\n\nfor(lib in deps){library(lib, character.only = TRUE)}\n\n\n\n\n\n\n\nImportant\n\n\n\nFurther instructions on how to download the workshop material from Github will be given during the workshop."
  },
  {
    "objectID": "overview.html#during-the-workshop",
    "href": "overview.html#during-the-workshop",
    "title": "Overview",
    "section": "During the workshop",
    "text": "During the workshop\nAll the workshop material will be made available on this website. Further instructions on how to download the material will be given during the workshop."
  },
  {
    "objectID": "data-description.html#introduction-to-digital-footprint-data",
    "href": "data-description.html#introduction-to-digital-footprint-data",
    "title": "1  Meta-Facebook data introduction",
    "section": "1.1 Introduction to digital footprint data",
    "text": "1.1 Introduction to digital footprint data\nA digital footprint refers to the trail of digital activities and information left by individuals as they interact with digital platforms and services (Rowe, Cabrera-Arnau, and Piestrostefani 2023). It encompasses data generated through online activities such as browsing history, social media interactions, location tracking, and other digital transactions. The cumulative collection of data forms a digital profile that provides insights into an individual’s online behavior, preferences, and activities. This data can also be aggregated to shed light into macro structural processes and trends, such as urban mobility, consumer demand, transport usage, population ageing and decline.\nIn particular, digital footprint data can be harnessed to analyse human mobility patterns, including patterns of internal mobility within a specific geographical area. By leveraging data from sources such as mobile devices, transportation apps, and geolocation services, we can gain a deeper understanding of how individuals move within a region. For example, digital footprint data can reveal the spatiotemporal patterns of commuting behaviour, the popularity of a certain route connecting two locations, the likelihood that a certain location experiences congestion at a certain time of the day, and even the impact of external factors such as weather conditions, public events or COVID-19 on mobility. Understanding human mobility patterns is therefore key to support fundamental human activities, including urban planning, transportation, service delivery, public health and sustainability. For an extended discussion of digital footprint data, see Rowe, Cabrera-Arnau, and Piestrostefani (2023)."
  },
  {
    "objectID": "data-description.html#meta-facebook-data",
    "href": "data-description.html#meta-facebook-data",
    "title": "1  Meta-Facebook data introduction",
    "section": "1.2 Meta-Facebook data",
    "text": "1.2 Meta-Facebook data\nThe social media platform Facebook, with its vast user base, offers unique advantages for analysing human mobility. In the course of providing services to their users, many smartphones and smartphone apps regularly collect precise location information. In the case of Facebook, people have an option of whether or not to provide this information to Facebook (“Learn about Your Location Privacy | Privacy Center | Manage Your Privacy on Facebook, Instagram and Messenger | Facebook Privacy”). Location data is used to provide a variety of services, including helping people find nearby friends, information about nearby Wi-Fi hotspots, and location-relevant ads. This data also enables targeting of AMBER alerts and prompts to check-in as “safe” after a hazard event. In addition to powering Facebook product features, this location data can provide insights about how populations are affected by hazard events as they happen (Maas et al. 2019).\nThrough Meta’s Data for Good programme, Facebook’s parent company, Meta Platforms Inc., provides tools built from privacy-protected data on the Facebook platform, as well as tools developed using commercially and publicly available sources like satellite imagery and census data. In particular, Data for Good has created two data sets, Facebook Population During Crisis and Facebook Movement During Crisis, that will be of use for this workshop.\nThese data sets make use of anonymised and aggregated data, including current and historical location data. While the raw data used for the creation of the data sets remains available only to the data owners, the aggregated data, with privacy and security protections is shared with non-profit organisations and researchers on an ongoing basis in the days and weeks following a hazard event (Maas et al. 2019)."
  },
  {
    "objectID": "data-description.html#meta-facebook-population-and-movement-data",
    "href": "data-description.html#meta-facebook-population-and-movement-data",
    "title": "1  Meta-Facebook data introduction",
    "section": "1.3 Meta-Facebook population and movement data",
    "text": "1.3 Meta-Facebook population and movement data\nBoth data sets Facebook Population and Facebook Movements contain data corresponding to a two-year period, starting in March 2020, and to four Latin American countries, Argentina, Chile, Colombia and Mexico.\nThe data in both data sets is temporally aggregated into three 8-hour windows (00:00–08:00, 08:00–16:00 and 16:00–00:00) for every day in the aforementioned two-year time period.\nIt is spatially aggregated into tiles according to the Bing Maps Tile System. This geospatial indexing system was developed by Microsoft and it partitions the world into square cells at various levels of resolution.\nThe Facebook Population data provide information on the number of active Facebook users in each tile.\nThe Facebook Movement data capture the total number of Facebook users moving between pairs of origin and destination Bing tiles.\nWe note here that due to the nature of the Facebook Movement data, we cannot distinguish between different types of movements, for example, daily commutes to work or permanent changes of address. However, we are still able to detect the evolution of movements between origin-destination pairs of Bing tiles and hence, we are able to capture the impact that COVID-19 has on mobility patterns.\nOn top of the data for the two-year period, each entry in the Facebook Population and Facebook Movements datasets include data for baseline levels before COVID-19. The baseline values are computed based on a 45-day period ending on the 10th of March of 2020.\nThe data sets also include a ‘quality’ score indicating the number of standard deviations by which the observed data at specific locations and time windows differ from the baseline values, hence highlighting statistically significant changes.\n\n1.3.1 Data generation\nPrior to releasing the above-mentioned datasets, Meta applies three techniques to ensure privacy and anonymisation. First, a small undisclosed amount of random noise is added to ensure that precise location cannot be identified for small population counts in sparsely populated areas. While removing small counts may lead to an underrepresentation of the population in these places, the geographic distribution of population is still reflected in the data. Second, spatial smoothing is applied to produce a smooth population count surface using inverse distance-weighted averaging. Third, any remaining population counts of less than 10 are removed from the final data set (see Maas et al. (2019) for details)."
  },
  {
    "objectID": "data-description.html#challenges-of-digital-footprint-data",
    "href": "data-description.html#challenges-of-digital-footprint-data",
    "title": "1  Meta-Facebook data introduction",
    "section": "1.4 Challenges of digital footprint data",
    "text": "1.4 Challenges of digital footprint data\nDespite the numerous advantages of using DFD to study the patterns of human mobility, the presence of biases in this type of data is usually regarded as a problematic issue. The biases in DFD usually stem from the fact that certain population groups may be more likely to use location-tracking technologies than others, for example, younger people or people living in urban areas. Therefore, DFD may not be representative of the entire population and as a result, the accuracy of analyses involving DFD may be hindered, especially when biases are not accounted for.\n\n\n\n\n“Learn about Your Location Privacy | Privacy Center | Manage Your Privacy on Facebook, Instagram and Messenger | Facebook Privacy.” https://www.facebook.com/privacy/guide/location/.\n\n\nMaas, Paige, Shankar Iyer, Andreas Gros, Wonhee Park, Laura McGorman, Chaya Nayak, and P. Alex Dow. 2019. “Facebook Disaster Maps: Aggregate Insights for Crisis Response & Recovery.” In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 3173. KDD ’19. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3292500.3340412.\n\n\nRowe, Francisco, Carmen Cabrera-Arnau, and Elisabetta Piestrostefani. 2023. Population Science. population-science.net."
  },
  {
    "objectID": "temporal-trends.html#dependencies",
    "href": "temporal-trends.html#dependencies",
    "title": "2  Temporal patterns",
    "section": "2.1 Dependencies",
    "text": "2.1 Dependencies\nTo analyse the data, we need R and the following R packages (see installation instructions on [R packages]). Once installed, you can use the R packages by loading them as libraries:\n\n# Load the tidyverse package for data manipulation and visualization\nlibrary(tidyverse)\n\n# Load the zoo package for working with time series data\nlibrary(zoo)\n\n# Load the mice package for multiple imputation of missing data\nlibrary(mice)\n\n# Load the ggthemes package for additional plot themes\nlibrary(ggthemes)"
  },
  {
    "objectID": "temporal-trends.html#sec-loading",
    "href": "temporal-trends.html#sec-loading",
    "title": "2  Temporal patterns",
    "section": "2.2 Data wrangling",
    "text": "2.2 Data wrangling\nWe start by looking at the temporal evolution of internal human mobility in Chile in the first few months after the first outbreak of COVID-19. To do so, we read the movement data corresponding to the months of May, June, July, August and September 2020. The data is stored as .rds files and can be read using the readRDS() function:\n\ndf_5 <- readRDS(\"./data/fb/movement_grid/2020_05_mov.rds\")\ndf_6 <- readRDS(\"./data/fb/movement_grid/2020_06_mov.rds\")\ndf_7 <- readRDS(\"./data/fb/movement_grid/2020_07_mov.rds\")\ndf_8 <- readRDS(\"./data/fb/movement_grid/2020_08_mov.rds\")\ndf_9 <- readRDS(\"./data/fb/movement_grid/2020_09_mov.rds\")\n\nSince we are interested in the evolution of trends in internal human mobility over this five-month period, we bind the data sets together using the function rbind(). This function appends datasets that share the same columns. We call the resulting data set df_mov.\n\n# Combine the data frames df_5, df_6, df_7, df_8, and df_9 into a single data frame\ndf_mov <- rbind(df_5, df_6, df_7, df_8, df_9)\n\nBut, what are the columns of df1, df2, df3, df4, df5 and df_mov? We can easily visualise a dataset and its contents with the glimpse() function. For example, for df_mov:\n\n# Display a concise summary of the data frame df_mov\nglimpse(df_mov)\n\nRows: 630,635\nColumns: 23\n$ geometry                     <chr> \"LINESTRING (-71.630859375 -36.5272625723…\n$ date_time                    <chr> \"2020-05-01 08:00:00\", \"2020-05-01 08:00:…\n$ start_polygon_id             <chr> \"60871\", \"60871\", \"60871\", \"60871\", \"6087…\n$ start_polygon_name           <chr> \"Ñuble\", \"Ñuble\", \"Ñuble\", \"Ñuble\", \"Ñubl…\n$ end_polygon_id               <chr> \"60871\", \"60871\", \"60871\", \"60871\", \"6087…\n$ end_polygon_name             <chr> \"Ñuble\", \"Ñuble\", \"Ñuble\", \"Ñuble\", \"Ñubl…\n$ length_km                    <dbl> 0.00000, 0.00000, 0.00000, 0.00000, 0.000…\n$ tile_size                    <dbl> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1…\n$ country                      <chr> \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\",…\n$ level                        <chr> \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"…\n$ n_crisis                     <dbl> 228, 455, 989, 2293, 111, 23, 22, 3045, 1…\n$ n_baseline                   <dbl> 236.2, 367.6, 1162.4, 1456.8, 92.6, 45.6,…\n$ n_difference                 <dbl> -8.2, 87.4, -173.4, 836.2, 18.4, -22.6, -…\n$ percent_change               <dbl> -3.456998, 23.711340, -14.904590, 57.3604…\n$ is_statistically_significant <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ z_score                      <dbl> -0.09754166, 1.02989015, -0.47284604, 4.0…\n$ start_lat                    <dbl> -36.64353, -36.64353, -36.64353, -36.6435…\n$ start_lon                    <dbl> -71.97498, -71.97498, -71.97498, -71.9749…\n$ end_lat                      <dbl> -36.64353, -36.64353, -36.64353, -36.6435…\n$ end_lon                      <dbl> -71.97498, -71.97498, -71.97498, -71.9749…\n$ start_quadkey                <chr> \"21023300110\", \"21023300110\", \"2102330011…\n$ end_quadkey                  <chr> \"21023300110\", \"21023300110\", \"2102330011…\n$ date_time2                   <dttm> 2020-05-01 02:00:00, 2020-05-01 02:00:00…\n\n\nIn the output, we first see the number of rows and columns in the data set. Then we see the name of each column, followed by the type of data stored in that column (e.g. <chr> for character), and a sample of the data values. Alternatively, if we only want to know the names of the columns, we can use the names() function:\n\n# Retrieve the names of the variables (columns) in the data frame df_mov\nnames(df_mov)\n\n [1] \"geometry\"                     \"date_time\"                   \n [3] \"start_polygon_id\"             \"start_polygon_name\"          \n [5] \"end_polygon_id\"               \"end_polygon_name\"            \n [7] \"length_km\"                    \"tile_size\"                   \n [9] \"country\"                      \"level\"                       \n[11] \"n_crisis\"                     \"n_baseline\"                  \n[13] \"n_difference\"                 \"percent_change\"              \n[15] \"is_statistically_significant\" \"z_score\"                     \n[17] \"start_lat\"                    \"start_lon\"                   \n[19] \"end_lat\"                      \"end_lon\"                     \n[21] \"start_quadkey\"                \"end_quadkey\"                 \n[23] \"date_time2\"                  \n\n\nAs you might have guessed, each column represents a variable or a characteristic of the data stored in the dataset. Each row or data point in the resulting dataset df_mov represents a population flow between an origin and a destination location, taking place during a given time window, in this case, within the five-month period starting in May 2020. The information about the origin and destination of the flow is fully determined by the geometry column. Other columns also contain information about the start and end locations of the movements, such as start_polygon_id, start_polygon_name, end_polygon_id, end_polygon_name, start_lat, start_lon, end_lat, end_lon, start_quadkey and end_quadkey. The information about the time window in which each population flow takes place is contained in the date_time column.\nIn the next few sections, we will focus only on three variables, namely, date_time, n_crisis and n_baseline. But first, let’s talk a bit more about the datetime format.\n\n2.2.1 Variable selection\nOf all the columns in the dataset df_mov, three of them are particularly relevant for the analysis in this section of the workshop, n_crisis, n_baseline and date_time. Firstly, the variable n_crisis gives us the size of a given flow, i.e. the number of people moving from an origin to a destination. For the first flow, this would be:\n\n# Retrieve the value of the variable 'n_crisis' from the first row of the data frame 'df_mov'\ndf_mov$n_crisis[[1]]\n\n[1] 228\n\n\nBut is this number large or small? In order to establish a benchmark, we can look at n_baseline. This variable tells us about the number of people that we would expect travelling from origin to destination on the same weekday at the same time of the day in normal conditions, i.e. pre-pandemic.\n\n# Retrieve the value of the variable 'n_baseline' from the first row of the data frame 'df_mov'\ndf_mov$n_baseline[[1]]\n\n[1] 236.2\n\n\nThe fact that the value of n_crisis is smaller than n_baseline for the first flow suggests that during the pandemic people were moving less between the particular origin-destination pair of locations corresponding to the first flow in the dataset.\nHowever, in order to draw conclusions at the population level, looking at a data point in isolation is not enough. We can gain much more meaningful insights if we look at much larger amounts of data as well as the temporal evolution of the observed patterns. To do this, we need to look into the date_time variable, that tells us the 8-hour time window in which a flow takes place. For example, we can look up the value of date_time for the first flow recorded in df_mov:\n\n# Accessing the value of the first element in the \"date_time\" column of the \"df_mov\" data frame\ndf_mov$date_time[[1]]\n\n[1] \"2020-05-01 08:00:00\"\n\n\nTherefore, the first flow in the dataset df_mov took place between 00:00 and 08:00 of the 1st of May 2020. However, for the analysis in this workbook, we are interested only in the patterns taking place at the daily scale, so the information regarding the time window within the day is irrelevant.\n\n\n2.2.2 Extracting calendar date\nTo explore the variation in the number of flows at the daily level, we need to first extract only the date from each movement. This can be done by running the code below, where we create a new column in df_mov named date. This new column stores only the information corresponding to date which can be obtained by applying the as.Date() function to the data from the date_time column. This function allows us to convert character data into objects of class Date representing calendar dates and following a specified format (in this case, year-month-day).\n\n# Converting the \"date_time\" column in the \"df_mov\" data frame to Date format\n# and assigning the result to a new column called \"date\"\ndf_mov$date <- as.Date(df_mov$date_time, format = \"%Y-%m-%d\")\n\n\n\n2.2.3 Temporally grouping data\nSince we are interested in the number of movements taking place on a daily basis, we need to aggregate the information from flows that take place on the same day. Specifically, we need to sum all the values of n_crisis corresponding to flows from the same day. This can be done, firstly, by passing the df_mov dataset to the group_by() function and specifying that we want to group the data according to the information stored in the df_mov$date column that we just created. This action can be achieved via the pipeline operator %>%, which simply feeds the results of one operation into the next operation. For those familiar with the mathematical language, the pipe operator is equivalent to the function composition operation. But the group_by() function alone will not give the desired output, so we follow it by the summarise() function with an appropriate action to perform, in this case the sum of the values of n_crisis for all the entries that share a date. The output is a dataset containing two columns, named total and df_mov$date. We rename the second column of the resulting dataset to date instead of df_mov$date. The final dataset is df_crisis.\n\n# Creating a new data frame called \"df_crisis\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov\" data frame by the \"date\" column\ndf_crisis <- df_mov %>%\n  group_by(df_mov$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_crisis\" column\n# and creating a new column called \"total\" to store the sum\n  summarise(total = sum(n_crisis)) %>%\n  \n# Renaming the \"df_mov$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov$date\")\n\nWe apply a very similar process to sum the values of n_baseline corresponding to flows from the same day. The resulting dataset is df_baseline.\n\n# Creating a new data frame called \"df_baseline\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov\" data frame by the \"date\" column\ndf_baseline <- df_mov %>%\n  group_by(df_mov$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_baseline\" column\n# and creating a new column called \"total\" to store the sum\n  summarise(total = sum(n_baseline)) %>%\n  \n# Renaming the \"df_mov$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov$date\")"
  },
  {
    "objectID": "temporal-trends.html#system-wide-analysis",
    "href": "temporal-trends.html#system-wide-analysis",
    "title": "2  Temporal patterns",
    "section": "2.3 System-wide analysis",
    "text": "2.3 System-wide analysis\nWith df_crisis and df_baseline, we are ready to create our first figure. The goal is to show the daily evolution of internal movements at the nation-wide scale in Chile during the five-month period starting in May 2020. Therefore, the figure will include information about the date on the x-axis and the number of movements on the y-axis. Furthermore, the figures should allow us to compare the trends in the period of interest with the baseline levels of internal mobility. Hence, our plot will include two components: a line showing the evolution of internal movements from May to September 2020 and a line representing the baseline.\nTo generate the figure, we use the ggplot2 package. First, ggplot() is used to construct the initial plot object, and is followed by a plus sign ( + ) to add components to the plot. Note that we add a legend to specify the component of the plot that refers to the “crisis” or pandemic period and the component that refers to the baseline.\n\n# Creating a line plot using ggplot\n\nggplot() +\n  \n  # Adding a line layer for the \"df_baseline\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"Baseline\"), \n            data = df_baseline, linewidth = 1.5) +\n  \n  # Adding a line layer for the \"df_crisis\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"Crisis\"),\n            data = df_crisis, linewidth = 1.5) +\n  \n  # Customizing the color scale manually\n  scale_color_manual(values = c(\"Crisis\" = \"red\", \"Baseline\" = \"blue\"),\n                     labels = c(\"Baseline\", \"Crisis\")) +\n  \n  # Customizing plot labels\n  labs(color = \"Legend\", \n       title = \"Figure 1: Temporal patterns in the number of movements in Chile\",\n       x = \"Date\",\n       y = \"Number of movements\") +\n  \n  # Applying the \"minimal\" theme\n  theme_minimal()\n\n\n\n\nWe can also plot the difference between the levels of internal migration during the pandemic period and the baseline. First we create a new dataset df_difference with a column named difference as follows:\n\n# Creating a new data frame called \"df_difference\" as a copy of \"df_crisis\"\ndf_difference <- df_crisis\n\n# Adding a new column called \"difference\" to \"df_difference\"\n# The values in this column are calculated as the difference between the \"total\" column of \"df_crisis\" and \"df_baseline\"\ndf_difference$difference <- df_crisis$total - df_baseline$total\n\nThen we generate a plot following a procedure as above:\n\n# Creating a line plot using ggplot\nggplot() +\n  \n  # Adding a line layer for the \"df_difference\" data\n  geom_line(mapping = aes(x = date, y = difference, color = \"Difference\"), \n            data = df_difference, linewidth = 1.5) +\n  \n  # Customizing the color scale manually\n  scale_color_manual(values = c(\"Difference\" = \"darkgreen\"),\n                     labels = c(\"Difference between crisis \\nand baseline\")) +\n  \n  # Customizing plot labels\n  labs(color = \"Legend\", \n       title = \"Figure 2: Temporal patterns in the number of movements in Chile\",\n       x = \"Date\",\n       y = \"Difference in number of movements\") +\n  \n  # Applying the \"minimal\" theme\n  theme_minimal() +\n  \n  # Modifying y-axis labels to display in full form with no space for thousands separator\n  scale_y_continuous(labels = scales::number_format(big.mark = \"\")) \n\n\n\n\n\n\n\n\n\n\nQuestion 1\nThe patterns during the crisis period, display an overall trend and some shorter-term oscillations. What do these oscillations correspond to?\n\n\n\n\n\n\n\n\n\nQuestion 2\nDoes the observed overall trend in the 5-month period starting in May 2020 agree with what you expected? You may answer this question based on your knowledge on the evolution of the COVID-19 pandemic in Chile."
  },
  {
    "objectID": "temporal-trends.html#santiago-internal-movements",
    "href": "temporal-trends.html#santiago-internal-movements",
    "title": "2  Temporal patterns",
    "section": "2.4 Santiago: Internal movements",
    "text": "2.4 Santiago: Internal movements\nUp to this point, we have focused on the temporal trends of internal mobility at the nation-wide scale. Thanks to the fine level of detail in our original datasets, we can focus the analysis on more specific areas or regions. In the remainder of this sections, we will analyse movements that involve Santiago, Chile’s capital city. As we pointed out in section Section 2.2, there are several columns in the dataset df_mov that contain information about the start and end locations of the movements. The spatial variability of internal population flows will be explored in more detail in the next section of the workshop. But for now, we will focus on the columns names start_polygon_name and end_polygon_name, which contain the name of the province where a flow starts or ends respectively.\n\n2.4.1 Santiago as destination\nHence, to obtain only the movements that have the province of Santiago as their destination, we need to filter the data set df_mov so that it only contains rows where the value of end_polygon_name is Santiago. In R, this can be done very simply by running the lines of code below. The first line, keeps only the flows that start outside of Santiago and stores the result in the df_mov_to dataset. The second line, keeps only the flows that end in Santiago and stores the result in the df_mov_to dataset. We call the resulting data set df_mov_to.\n\n# Filtering the \"df_mov\" data frame to select rows where \"start_polygon_name\" is not 'Santiago'}\ndf_mov_to <- filter(df_mov, start_polygon_name != 'Santiago')\n\n# Further filtering the \"df_mov_to\" data frame to select rows where \"end_polygon_name\" is 'Santiago'\ndf_mov_to <- filter(df_mov_to, end_polygon_name == 'Santiago')\n\nThen, like before, we create a new column for df_mov_to containing only information about the date (and not the time) in year-month-day format:\n\n# Converting the \"date_time\" column in the \"df_mov_to\" data frame to Date format\n# and assigning the result to a new column called \"date\"\ndf_mov_to$date <- as.Date(df_mov_to$date_time, format = \"%Y-%m-%d\")\n\nand we follow this action by grouping the data by date. We generate the datasets df_to_crisis and df_to_baseline, which contain the sum of the values of n_crisis and n_baseline for flows that happen on the same day:\n\n# Creating a new data frame called \"df_to_crisis\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_to\" data frame by the \"date\" column\ndf_to_crisis <- df_mov_to %>%\n  group_by(df_mov_to$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_crisis\" column\n# and creating a new column called \"total\" to store the sum\n  summarise(total = sum(n_crisis)) %>%\n  \n# Renaming the \"df_mov_to$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_to$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\n\n# Grouping the rows of the \"df_mov_to\" data frame by the \"date\" column\ndf_to_baseline <- df_mov_to %>%\n  group_by(df_mov_to$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_baseline\" column\n# and creating a new column called \"total\" to store the sum\n  summarise(total = sum(n_baseline)) %>%\n  \n# Renaming the \"df_mov_to$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_to$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\nWith all these elements, we can generate a figure showing the trends in the number of movements from any province outside of Santiago to Santiago, both during the 5-month crisis period during the pandemic and during the baseline period:\n\n# Creating a line plot using ggplot\nggplot() +\n  \n  # Adding a line layer for the \"df_to_baseline\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"Baseline\"), \n            data = df_to_baseline, linewidth = 1.5) +\n  \n  # Adding a line layer for the \"df_to_crisis\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"Crisis\"),\n            data = df_to_crisis, linewidth = 1.5) +\n  \n  # Customizing the color scale manually\n  scale_color_manual(values = c(\"Crisis\" = \"magenta\", \"Baseline\" = \"blue\"),\n                     labels = c(\"Baseline\", \"Crisis\")) +\n  \n  # Customizing plot labels\n  labs(color = \"Legend\", \n       title = \"Figure 3: Temporal patterns in the number of movements to Santiago\",\n       x = \"Date\",\n       y = \"Number of movements\") +\n  \n  # Applying the \"minimal\" theme\n  theme_minimal()\n\n\n\n\n\n\n2.4.2 Santiago as origin\nAn analogous analysis can be carried out for movements with origin in the province of Santiago and destination elsewhere. To do this, we follow exactly the same steps as before but modifying the way in which we filter df_mov, and replacing the names of new variables where appropriate (e.g. df_mov_from instead of df_mov_to):\n\n# Filtering the \"df_mov\" data frame to select rows where \"start_polygon_name\" is 'Santiago'\ndf_mov_from <- filter(df_mov, start_polygon_name == 'Santiago')\n\n# Further filtering the \"df_mov_from\" data frame to select rows where \"end_polygon_name\" is not 'Santiago'\ndf_mov_from <- filter(df_mov_from, end_polygon_name != 'Santiago')\n\n\n# Converting the \"date_time\" column in the \"df_mov_from\" data frame to Date format\n# and assigning the result to a new column called \"date\"\ndf_mov_from$date <- as.Date(df_mov_from$date_time, format = \"%Y-%m-%d\")\n\n\n# Creating a new data frame called \"df_from_crisis\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_from\" data frame by the \"date\" column\ndf_from_crisis <- df_mov_from %>%\n  group_by(df_mov_from$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_crisis\" column\n# and creating a new column called \"total\" to store the sum\n  summarise(total = sum(n_crisis)) %>%\n  \n# Renaming the \"df_mov_from$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_from$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\n\n# Creating a new data frame called \"df_from_baseline\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_from\" data frame by the \"date\" column\ndf_from_baseline <- df_mov_from %>%\n  group_by(df_mov_from$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_baseline\" column\n# and creating a new column called \"total\" to store the sum\n  summarise(total = sum(n_baseline)) %>%\n  \n# Renaming the \"df_mov_from$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_from$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\n\n# Creating a line plot using ggplot\nggplot() +\n  \n  # Adding a line layer for the \"df_from_baseline\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"Baseline\"), \n            data = df_from_baseline, linewidth = 1.5) +\n  \n  # Adding a line layer for the \"df_from_crisis\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"Crisis\"),\n            data = df_from_crisis, linewidth = 1.5) +\n  \n  # Customizing the color scale manually\n  scale_color_manual(values = c(\"Crisis\" = \"darkcyan\", \"Baseline\" = \"blue\"),\n                     labels = c(\"Baseline\", \"Crisis\")) +\n  \n  # Customizing plot labels\n  labs(color = \"Legend\", \n       title = \"Figure 4: Temporal patterns in the number of movements from Santiago\",\n       x = \"Date\",\n       y = \"Number of movements\") +\n\n  # Applying the \"minimal\" theme\n  theme_minimal()\n\n\n\n\nWe can also compare the movements to and from Santiago province, this time omitting the baseline trends for clarity:\n\n# Creating a line plot using ggplot\nggplot() +\n  \n  # Adding a line layer for the \"df_to_crisis\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"To\"), \n            data = df_to_crisis, size = 1.5) +\n  \n  # Adding a line layer for the \"df_from_crisis\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"From\"),\n            data = df_from_crisis, size = 1.5) +\n  \n  # Customizing the color scale manually\n  scale_color_manual(values = c(\"To\" = \"magenta\", \"From\" = \"darkcyan\"),\n                     labels = c(\"From Santiago\", \"To Santiago\")) +\n  \n  # Customizing plot labels\n  labs(color = \"Legend\", \n       title = \"Figure 5: Temporal patterns in the number of movements to and from Santiago\",\n       x = \"Date\",\n       y = \"Number of movements\") + \n  \n  # Applying the \"minimal\" theme\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nQuestion 3\nDoes the overall trend in the internal movements involving Santiago province agree with your intuition?\n\n\n\n\n\n\n\n\n\nQuestion 4\nCan you observe any differences in the shorter-term oscillations corresponding to movements to and from Santiago province? To answer this question, it might be helpful to complete the Exercise below.\n\n\n\n\n\n\n\n\n\nExercise 1\nCreate a plot analogous to Figure 5, but comparing the baseline movements instead of the movements during the crisis period.\n\n\n\n\n\n2.4.3 Santiago-Valparaíso movements\nIt is possible to look at movements beetween a specified origin and destination. Here, we focus on the flow of people between Santiago and a popular destination province for Santiaguinos, Valparaíso. To explore the movements from Santiago to Valparaíso, you can run the code below:\n\n# Filtering the \"df_mov\" data frame to select rows where \"start_polygon_name\" is 'Santiago'\ndf_mov_between1 <- filter(df_mov, start_polygon_name == 'Santiago')\n\n# Further filtering the \"df_mov_between1\" data frame to select rows where \"end_polygon_name\" is 'Valparaíso'\ndf_mov_between1 <- filter(df_mov_between1, end_polygon_name == 'Valparaíso')\n\n\n# Converting the \"date_time\" column in the \"df_mov_between1\" data frame to Date format\n# and assigning the result to a new column called \"date\"\ndf_mov_between1$date <- as.Date(df_mov_between1$date_time, format = \"%Y-%m-%d\")\n\n\n# Creating a new data frame called \"df_between1_crisis\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_between1\" data frame by the \"date\" column\ndf_between1_crisis <- df_mov_between1 %>%\n  group_by(df_mov_between1$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_crisis\" column\n# and creating a new column called \"total\" to store the sum\n  summarise(total = sum(n_crisis)) %>%\n  \n# Renaming the \"df_mov_between1$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_between1$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\n\n# Creating a new data frame called \"df_between1_baseline\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_between1\" data frame by the \"date\" column\ndf_between1_baseline <- df_mov_between1 %>%\n  group_by(df_mov_between1$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_baseline\" column\n# and creating a new column called \"total\" to store the sum\n  summarise(total = sum(n_baseline)) %>%\n  \n# Renaming the \"df_mov_between1$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_between1$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\n\n# Creating a line plot using ggplot\nggplot() +\n  \n  # Adding a line layer for the \"df_between1_baseline\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"Baseline\"), \n            data = df_between1_baseline, size = 1.5) +\n  \n  # Adding a line layer for the \"df_between1_crisis\" data\n  geom_line(mapping = aes(x = date, y = total, color = \"Crisis\"),\n            data = df_between1_crisis, size = 1.5) +\n  \n  # Customizing the color scale manually\n  scale_color_manual(values = c(\"Crisis\" = \"magenta\", \"Baseline\" = \"blue\"),\n                     labels = c(\"Baseline\", \"Crisis\")) +\n  \n  # Customizing plot labels\n  labs(color = \"Legend\", \n       title = \"Figure 6: Temporal patterns in the number of movements from Santiago to Valparaíso\",\n       x = \"Date\",\n       y = \"Number of movements\") + \n  \n  # Applying the \"minimal\" theme\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nQuestion 5\nDoes the overall trend in the internal movements from Santiago to Valparaíso in this time period agree with your intuition?\n\n\n\n\n\n\n\n\n\nExercise 2\nCreate a plot analogous to Figure 6, but comparing the movements from Valparaíso to Santiago during the crisis and baseline period.\n\n\n\n\n\n\n\n\n\nExercise 3\nCompare the trends in movements from Santiago to Valparaíso and from Valparaíso to Santiago. Are the overall trends similar? Are there differentces in the shorter-term fluctuations?"
  },
  {
    "objectID": "temporal-trends.html#relationship-between-movements-and-active-facebook-user-population",
    "href": "temporal-trends.html#relationship-between-movements-and-active-facebook-user-population",
    "title": "2  Temporal patterns",
    "section": "2.5 Relationship between movements and active Facebook user population",
    "text": "2.5 Relationship between movements and active Facebook user population\nSo far, we have looked at the 5-month period starting in May 2020 and spanning throughout the Chilean winter. But, as mentioned at the beginning of the workbook, Facebook Meta collected data for Chile in the two-year period spanning from the end of March of 2020 to the end of March 2022. As we saw in Section 2.2, the data is organised in files by month, and we can load them individually. However, since we are going to look at many months, we can automate the data-reading process. This is done by first, specifying the path to the folder where the movement data files are stored, and then, using a for loop to read each of the files in the folder and bind them together. Getting a full understanding of the code below is out of the scope of this workshop, but we have included comments starting with the ( # ) symbol to indicate what each line of code does in case you are curious.\n\n# Get a list of file paths in the folder\nfolder_path <- \"./data/fb/movement_grid/\"\nfile_paths <- list.files(path = folder_path, pattern = \"\\\\.rds$\", full.names = TRUE)\n\n# Create an empty list to store the data frames\ndfs <- list()\n\n# Loop through the file paths\nfor (file_path in file_paths) {\n  # Read each file as a data frame\n  df <- readRDS(file_path)\n  # Store the data frame in the list\n  dfs <- append(dfs, list(df))\n}\n\n# Bind all the data frames into a single data frame\ndf_mov_full <- bind_rows(dfs)\n\nIn the previous sections, we have focused on analysing movement data during the pandemic and comparing it to a baseline period. While some insights can be gained by looking only at this data, it is important to consider the number of active Facebook users. The reason for this can be illustrated through the following examples. Suppose that the number of Facebook users drops to zero, then no movements would be recorded. However, this does not mean there are no movements taking place. Conversely, suppose Facebook becomes very popular and the whole population starts using it, then more movements would probably be recorded but this does not mean that people started moving more. Hence, it can be very useful to look at the number of movements per active user and analyse how this quantity evolves both during the pandemic and the baseline.\nBelow, we load data for the population of active Facebook users:\n\n# Get a list of file paths in the folder\nfolder_path <- \"data/fb/population_grid/\"\nfile_paths <- list.files(path = folder_path, pattern = \"\\\\.rds$\", full.names = TRUE)\n\n# Create an empty list to store the data frames\ndfs <- list()\n\n# Loop through the file paths\nfor (file_path in file_paths) {\n  # Read each file as a data frame\n  df <- readRDS(file_path)\n  \n  # Store the data frame in the list\n  dfs <- append(dfs, list(df))\n}\n\n# Bind all the data frames into a single data frame\ndf_mov_full_pop <- bind_rows(dfs)\n\n\n2.5.1 Data preparation\nLike the movement datasets, the Facebook population data is aggregated into 8-hour time windows but here, we are only interested in the variation at the daily level. Therefore, we group by date the number of movements and the number of active users during the crisis period.\n\n# Converting the \"date_time\" column in the \"df_mov_full\" data frame to Date format\n# and assigning the result to a new column called \"date\"\ndf_mov_full$date <- as.Date(df_mov_full$date_time, format = \"%Y-%m-%d\")\n\n\n# Converting the \"date_time\" column in the \"df_mov_full_pop\" data frame to Date format\n# and assigning the result to a new column called \"date\"\ndf_mov_full_pop$date <- as.Date(df_mov_full_pop$date_time, format = \"%Y-%m-%d\")\n\n\n# Creating a new data frame called \"df_mov_full_crisis\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_full\" data frame by the \"date\" column\ndf_mov_full_crisis <- df_mov_full %>%\n  group_by(df_mov_full$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_crisis\" column\n# and creating a new column called \"n_crisis\" to store the sum\n  summarise(n_crisis = sum(n_crisis)) %>%\n  \n# Renaming the \"df_mov_full$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_full$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\n\n# Creating a new data frame called \"df_mov_full_pop_crisis\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_full_pop\" data frame by the \"date\" column\ndf_mov_full_pop_crisis <- df_mov_full_pop %>%\n  group_by(df_mov_full_pop$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_crisis\" column\n# and creating a new column called \"pop_n_crisis\" to store the sum\n  summarise(pop_n_crisis = sum(n_crisis)) %>%\n  \n# Renaming the \"df_mov_full_pop$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_full_pop$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\nOnce the grouping by date is done, we merge the resulting datasets for movements and population of active Facebook users according to the date column:\n\n# Merging the \"df_mov_full_crisis\" and \"df_mov_full_pop_crisis\" data frames based on the \"date\" column\n# and assigning the result to a new data frame called \"df_full_crisis\"\ndf_full_crisis <- merge(df_mov_full_crisis, df_mov_full_pop_crisis, by = \"date\", all.x = TRUE)\n\nThe original data for the population of active Facebook users is missing some dates, so we estimate the missing data using Multivariate Imputation by Chained Equations (with the mice package).\n\n# Create a mice object with only the column you want to impute\ndf_to_complete <- mice(df_full_crisis[, -which(names(df_full_crisis) == \"n_crisis\")])\n\n\n iter imp variable\n  1   1  pop_n_crisis\n  1   2  pop_n_crisis\n  1   3  pop_n_crisis\n  1   4  pop_n_crisis\n  1   5  pop_n_crisis\n  2   1  pop_n_crisis\n  2   2  pop_n_crisis\n  2   3  pop_n_crisis\n  2   4  pop_n_crisis\n  2   5  pop_n_crisis\n  3   1  pop_n_crisis\n  3   2  pop_n_crisis\n  3   3  pop_n_crisis\n  3   4  pop_n_crisis\n  3   5  pop_n_crisis\n  4   1  pop_n_crisis\n  4   2  pop_n_crisis\n  4   3  pop_n_crisis\n  4   4  pop_n_crisis\n  4   5  pop_n_crisis\n  5   1  pop_n_crisis\n  5   2  pop_n_crisis\n  5   3  pop_n_crisis\n  5   4  pop_n_crisis\n  5   5  pop_n_crisis\n\n# Perform the imputation\ndf_complete_crisis <- complete(df_to_complete)\n\n# Assign the imputed values from the completed data frame to the original \"df_full_crisis\" data frame\ndf_full_crisis$pop_n_crisis <- df_complete_crisis$pop_n_crisis\n\nSimilarly, we group by date the number of movements and the number of active users during the baseline. Then, we merge the resulting datasets for movements and population of active Facebook users according to the date column and finally, we estimate any missing values using Multivariate Imputation by Chained Equations (with the mice package).\n\n# Creating a new data frame called \"df_mov_full_baseline\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_full\" data frame by the \"date\" column\ndf_mov_full_baseline <- df_mov_full %>%\n  group_by(df_mov_full$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_baseline\" column\n# and creating a new column called \"n_baseline\" to store the sum\n  summarise(n_baseline = sum(n_baseline)) %>%\n  \n# Renaming the \"df_mov_full$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_full$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\n\n# Creating a new data frame called \"df_mov_full_pop_baseline\" by performing the following operations:\n\n# Grouping the rows of the \"df_mov_full_pop\" data frame by the \"date\" column\ndf_mov_full_pop_baseline <- df_mov_full_pop %>%\n  group_by(df_mov_full_pop$date) %>%\n  \n# Summarizing the grouped data by calculating the total sum of the \"n_baseline\" column\n# and creating a new column called \"pop_n_baseline\" to store the sum\n  summarise(pop_n_baseline = sum(n_baseline)) %>%\n  \n# Renaming the \"df_mov_full_pop$date\" column as \"date\" in the resulting data frame\n  rename(\"date\" = \"df_mov_full_pop$date\") %>%\n  \n# Ungrouping the data frame to remove the grouping structure\n  ungroup()\n\n\n# Merging the \"df_mov_full_baseline\" and \"df_mov_full_pop_baseline\" data frames based on the \"date\" column\n# and assigning the result to a new data frame called \"df_full_baseline\"\ndf_full_baseline <- merge(df_mov_full_baseline, df_mov_full_pop_baseline, by = \"date\", all.x = TRUE)\n\n\n# Create a mice object with only the column you want to impute\ndf_to_complete <- mice(df_full_baseline[, -which(names(df_full_baseline) == \"n_baseline\")])\n\n\n iter imp variable\n  1   1  pop_n_baseline\n  1   2  pop_n_baseline\n  1   3  pop_n_baseline\n  1   4  pop_n_baseline\n  1   5  pop_n_baseline\n  2   1  pop_n_baseline\n  2   2  pop_n_baseline\n  2   3  pop_n_baseline\n  2   4  pop_n_baseline\n  2   5  pop_n_baseline\n  3   1  pop_n_baseline\n  3   2  pop_n_baseline\n  3   3  pop_n_baseline\n  3   4  pop_n_baseline\n  3   5  pop_n_baseline\n  4   1  pop_n_baseline\n  4   2  pop_n_baseline\n  4   3  pop_n_baseline\n  4   4  pop_n_baseline\n  4   5  pop_n_baseline\n  5   1  pop_n_baseline\n  5   2  pop_n_baseline\n  5   3  pop_n_baseline\n  5   4  pop_n_baseline\n  5   5  pop_n_baseline\n\n# Perform the imputation\ndf_complete_baseline <- complete(df_to_complete)\n\n# Assign the imputed values from the completed data frame to the original \"df_full_baseline\" data frame\ndf_full_baseline$pop_n_baseline <- df_complete_baseline$pop_n_baseline\n\nThe merged datasets for the crisis period and the baseline can be merged according to the date column:\n\n# Merging the \"df_full_crisis\" and \"df_full_baseline\" data frames based on the \"date\" column\n# and assigning the result to a new data frame called \"df_full\"\ndf_full <- merge(df_full_crisis, df_full_baseline, by = \"date\", all.x = TRUE)\n\nTo obtain the number of movements per active Facebook user on a given date, we can divide the number of movements on that date by the total number of active Facebook users on the same date. This can be done for both the crisis and baseline periods and the results can be stored in new columns. Furthermore, we compute the difference in the number of movements per active Facebook user between the crisis and baseline periods and store it in the difference_div column:\n\n# Calculating the division of \"n_crisis\" by \"pop_n_crisis\" and assigning the result to a new column \"n_crisis_div\"\ndf_full$n_crisis_div <- df_full$n_crisis / df_full$pop_n_crisis\n\n# Calculating the division of \"n_baseline\" by \"pop_n_baseline\" and assigning the result to a new column \"n_baseline_div\"\ndf_full$n_baseline_div <- df_full$n_baseline / df_full$pop_n_baseline\n\n# Calculating the difference between \"n_crisis_div\" and \"n_baseline_div\" and assigning the result to a new column \"n_difference_div\"\ndf_full$n_difference_div <- df_full$n_crisis_div - df_full$n_baseline_div\n\n\n\n2.5.2 Analysing trends\nBelow we plot the baseline number of tracked movements and Facebook active users as well as the same quantities for the crisis period:\n\n# Creating a line plot using ggplot\nggplot() +\n  \n  # Adding a line layer for the \"n_baseline\" data with color \"Baseline\"\n  geom_line(mapping = aes(x = date, y = n_baseline, color = \"Baseline\"), \n            data = df_full, size = 1.5) +\n  \n  # Adding a line layer for the \"n_crisis\" data with color \"Crisis\"\n  geom_line(mapping = aes(x = date, y = n_crisis, color = \"Crisis\"),\n            data = df_full, size = 1.5) +\n  \n  # Adding a line layer for the \"pop_n_baseline\" data with color \"Baseline FB users\"\n  geom_line(mapping = aes(x = date, y = pop_n_baseline, color = \"Baseline FB users\"),\n            data = df_full, size = 1.5) +\n  \n  # Adding a line layer for the \"pop_n_crisis\" data with color \"Crisis FB users\"\n  geom_line(mapping = aes(x = date, y = pop_n_crisis, color = \"Crisis FB users\"),\n            data = df_full, size = 1.5) +\n  \n  # Customizing the color scale manually with the respective colors and labels\n  scale_color_manual(values = c(\"Crisis\" = \"red\", \"Baseline\" = \"blue\", \"Crisis FB users\" = \"magenta\", \"Baseline FB users\" = \"cyan\"),\n                     labels = c(\"Baseline movements\", \"Baseline FB users\", \"Crisis movements\", \"Crisis FB users\")) +\n  \n  # Customizing plot labels\n  labs(color = \"Legend\", \n       title = \"Figure 7: Number of tracked movements \\nand active Facebook users in Chile\",\n       x = \"Date\",\n       y = \"Number of movements/users\") + \n  \n  # Applying the \"minimal\" theme\n  theme_minimal()\n\n\n\n\nDisregarding the spikes which are likely due to anomalies in the data collection process applied by Facebook, we observe that, generally speaking, both the baseline number of movements and the number of active Facebook users remain constant through the plotted period. In the case of the number of movements and the number of active Facebook users during the pandemic, they both experience a decline. But, is the decline observed in the number of movements a result of the decline in the number of active Facebook users? To answer this question, we can plot the number of tracked movements per active Facebook user, both for the baseline and the pandemic period. We can also plot the difference between these two quantities:\n\n# Creating a line plot using ggplot\nggplot() +\n  \n  # Adding a line layer for the \"n_baseline_div\" data with color \"Baseline movements per user\"\n  geom_line(mapping = aes(x = date, y = n_baseline_div, color = \"Baseline movements per user\"), \n            data = df_full, size = 1.5) +\n  \n  # Adding a line layer for the \"n_crisis_div\" data with color \"Crisis movements per user\"\n  geom_line(mapping = aes(x = date, y = n_crisis_div, color = \"Crisis movements per user\"),\n            data = df_full, size = 1.5) +\n  \n  # Adding a line layer for the \"n_difference_div\" data with color \"Difference\"\n  geom_line(mapping = aes(x = date, y = n_difference_div, color = \"Difference\"),\n            data = df_full, size = 1.5) +\n  \n  # Customizing the color scale manually with the respective colors and labels\n  scale_color_manual(values = c(\"Crisis movements per user\" = \"red\", \"Baseline movements per user\" = \"blue\", \"Difference\" = \"darkgreen\"),\n                     labels = c(\"Baseline movements per user\", \"Crisis movements per user\", \"Difference\")) +\n  \n  # Expanding the y-axis limits to include 0\n  expand_limits(y = 0) +\n  \n  # Customizing plot labels\n  labs(color = \"Legend\", \n       title = \"Figure 8: Number of tracked movements per active Facebook user in Chile\",\n       x = \"Date\",\n       y = \"Number of movements per active user\") + \n  \n  # Applying the \"minimal\" theme\n  theme_minimal()\n\n\n\n\nThis last figure shows that since the start of the pandemic, the number of movements per active Facebook user has been consistently lower than during the baseline period. However, the difference in trends between the crisis and basline periods is not as large as it might have been suggested by looking at the raw number of movements without taking into account the active population of users (e.g. the line corresponding to the number of movements during the crisis period from Figure 7)."
  },
  {
    "objectID": "spatial-patterns.html#aims",
    "href": "spatial-patterns.html#aims",
    "title": "3  Spatial patterns",
    "section": "3.1 Aims",
    "text": "3.1 Aims\nThis session aims to provide an illustration on how to (1) analyse the spatial patterns of origin-destination mobility flow data extracted from Meta-Facebook; (2) compute basic area-based indicators of human mobility; (3) handle spatial datasets in R; and, (4) create geospatial visualisations to examine and effectively communicate human mobility patterns. We start by clearing our R environment by running:\n\n#clean environment\nrm(list=ls())"
  },
  {
    "objectID": "spatial-patterns.html#dependencies",
    "href": "spatial-patterns.html#dependencies",
    "title": "3  Spatial patterns",
    "section": "3.2 Dependencies",
    "text": "3.2 Dependencies\nWe ensure to load the libraries below. A core area of this session is learning to work with spatial data in R. R offers an ecosystem of purposely designed packages for manipulation of spatial data and spatial analysis techniques. These ecosystem is known a r-spatial. Various packages exist in CRAN (The Comprehensive R Archive Network), including sf (E. Pebesma 2018, 2022a), stars (E. Pebesma 2022b), terra, s2 (Dunnington, Pebesma, and Rubak 2023), lwgeom (E. Pebesma 2023), gstat (E. J. Pebesma 2004; E. Pebesma and Graeler 2022), spdep (Bivand 2022), spatialreg (Bivand and Piras 2022), spatstat (Baddeley, Rubak, and Turner 2015; Baddeley, Turner, and Rubak 2022), tmap (Tennekes 2018, 2022), mapview (Appelhans et al. 2022) and more. A key package is this ecosystem is sf (E. Pebesma and Bivand 2023). R package sf provides a table format for simple features, where feature geometries are stored in a list-column.It appears in 2016 and was developed to move spatial data analysis in R closer to standards-based approaches seen in the industry and open source projects, to build upon more modern versions of open source geospatial software stack and allow for integration of R spatial software with the tidyverse (Wickham et al. 2019), particularly ggplot2, dplyr, and tidyr.\n\n# data wrangling\nlibrary(tidyverse)\n\n# spatial data wrangling\nlibrary(sf)\n\n# data visualisation\nlibrary(viridis) \n\n# format data visualisations\nlibrary(ggthemes)\nlibrary(patchwork)\nlibrary(showtext)\nlibrary(scales)\n\n# create maps\nlibrary(leaflet)\nlibrary(tmap)\nlibrary(mapdeck)"
  },
  {
    "objectID": "spatial-patterns.html#data",
    "href": "spatial-patterns.html#data",
    "title": "3  Spatial patterns",
    "section": "3.3 Data",
    "text": "3.3 Data\nHere we read all the data needed for the analysis. We use two types of data: (1) human mobility derived from Meta-Facebook users; and, administrative boundary data for Chile.\n\n3.3.1 Meta-Facebook mobility data\nWe use origin-destination mobility flow data between Provinces in Chile. We use data for April 2020. For a detailed description of the Meta-Facebook mobility data, please see the Meta-Facebook data introduction. We start by reading the data. We filter only flows occurring within the boundaries of Chile. The dataset contains daily flow counts between provinces that occurred in April 2020 during three windows of time during the day; that is, between 12am, 8am and 4pm.\nWe have a look at the data frame. We can see that the data contains 20 columns and 29,491 origin-destination interactions capturing counts of movements between provinces.\n\n# read\ndf20 <- readRDS(\"./data/fb/movement_adm/2020_04.rds\") %>% \n  dplyr::filter(country == \"CL\")\nglimpse(df20)\n\nRows: 29,491\nColumns: 20\n$ GEOMETRY                     <chr> \"LINESTRING (-69.96872527689874 -23.40113…\n$ date_time                    <chr> \"2020-04-01 00:00\", \"2020-04-01 00:00\", \"…\n$ start_polygon_id             <chr> \"60845\", \"60862\", \"60845\", \"60862\", \"6086…\n$ start_polygon_name           <chr> \"Antofagasta\", \"Cardenal Caro\", \"Antofaga…\n$ end_polygon_id               <chr> \"60847\", \"60890\", \"60846\", \"60863\", \"6089…\n$ end_polygon_name             <chr> \"Tocopilla\", \"Melipilla\", \"El Loa\", \"Colc…\n$ length_km                    <dbl> 139.7543134, 24.0764953, 100.3339392, 24.…\n$ tile_size                    <dbl> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1…\n$ country                      <chr> \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\",…\n$ level                        <chr> \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"…\n$ n_crisis                     <dbl> 79, 18, 320, 71, NA, 369, NA, 20, 11, NA,…\n$ n_baseline                   <dbl> 59.50, 25.50, 671.00, 132.75, NA, 559.25,…\n$ n_difference                 <dbl> 19.50, -7.50, -351.00, -61.75, NA, -190.2…\n$ percent_change               <dbl> 32.231405, -28.301887, -52.232143, -46.16…\n$ is_statistically_significant <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ z_score                      <dbl> 2.0148470, -0.6837043, -4.0000000, -1.261…\n$ start_lat                    <dbl> -24.32798, -34.32667, -24.32798, -34.3266…\n$ start_lon                    <dbl> -69.56718, -71.78028, -69.56718, -71.7802…\n$ end_lat                      <dbl> -22.06894, -33.75413, -22.81611, -34.7036…\n$ end_lon                      <dbl> -69.60081, -71.19829, -68.20015, -71.0631…\n\n\nWe can identify the list of origin and destination provinces for which we can observe movement.\n\nunique_origins <- unique(df20$start_polygon_name)\nunique_destinations <- unique(df20$end_polygon_name)\n\n\n\n3.3.2 Meta-Facebook active users population\nWe will also use information on the number of Meta-Facebook active users population. The population Meta-Facebook active users can vary over time reflecting their varying patterns of usage and internet accessibility.\n\n# read and select observations\npop20_df <- readRDS(\"./data/fb/population_adm/2020_04.rds\") %>% \n  dplyr::filter(country == \"CL\")\n\n# identify polygons\nunique_areas <- unique(pop20_df$polygon_name)\n\n# data overview\nglimpse(pop20_df)\n\nRows: 4,950\nColumns: 14\n$ spaco_id         <dbl> 60870, 60859, 60893, 60862, 60872, 60850, 60869, 6086…\n$ country          <chr> \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\",…\n$ polygon_name     <chr> \"Bío-Bío\", \"San Antonio\", \"Ranco\", \"Cardenal Caro\", \"…\n$ level            <chr> \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"LE…\n$ date_time        <chr> \"2020-04-01 00:00\", \"2020-04-01 00:00\", \"2020-04-01 0…\n$ n_baseline       <dbl> 35459.9167, 25048.9167, 8326.1780, 6164.6667, 68088.1…\n$ n_crisis         <dbl> 34606, 18033, 7336, 4034, 60602, 6632, 11397, 11397, …\n$ density_baseline <dbl> 0.014799224, 0.010454185, 0.003474937, 0.002572828, 0…\n$ density_crisis   <dbl> 0.014445053, 0.007527239, 0.003062154, 0.001683851, 0…\n$ n_difference     <dbl> -853.91667, -7015.91667, -990.17805, -2130.66667, -74…\n$ percent_change   <dbl> -2.40805018, -28.00774454, -11.89091959, -34.55695518…\n$ clipped_z_score  <dbl> -0.70353211, -1.45851614, -1.20047618, -1.29612464, -…\n$ lat              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lon              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\n\n3.3.3 Bing tiles\nMeta-Facebook data captured during the COVID-19 outbreak were available into two formats, at the level of Bing tiles and at the level of administrative areas. While we will be using data at the provincial level, you may be interested in having a peek at the tiles. The Bing Maps Tile System was developed by Microsoft. This system defines a series of grids at different resolution levels over a rectangular projection of the world, comprising 23 different levels of detail (Schwartz et al. 2009). Each level is constructed by dividing the previous level into fourths, with the most granular level being Level 1. Meta-Facebook data are typically produced at Bing tile levels 13 through 16, where level 13 results in tiles that are about 4.9 x 4.9 km at the Equator.\n\n\n\n\n\n\nNote\n\n\n\nIn our work in the project RECAST, we use this tile system and analyse the spatial patterns of human mobility in four Latin American countries, including Argentina, Chile, Colombia and Mexico. We expect to be in a position to share our final results with you soon. If you are interested, please do get in touch. For now, we share some of our share using Meta-Facebook data: Rowe et al. (2022), and research on the same line: González-Leonardo et al. (2022), González-Leonardo, Rowe, and Fresolone-Caparrós (2022), González-Leonardo and Rowe (2022), Wang et al. (2022) and Rowe, González-Leonardo, and Champion (2023).\n\n\nWe now read the shapefile containing the Bing tiles, simplify their boundaries and confirm it is valid. We display the boundaries for Chile and selected regions in the north, central and south of the country, to provide a better understanding of their size and areas of coverage.\n\n# read bing tiles\nbing_grid <- read_sf(\"./data/shp/grid/chile_grid.shp\") %>% \n  st_simplify(preserveTopology =T, # simplify boundaries\n              dTolerance = 1000) %>%  # 1km\n  sf::st_make_valid() # check the geometry is valid\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe created the Bing tiles. They are not available as polygons. They are only provided as rasters and not easily accessible.\n\n\n\n\n3.3.4 Administrative areas\nWe now read the boundaries for Chilean provinces. Provinces are the second administrative level in the country. Provinces are amalgamations of municipalities or comunes, and groupings of provinces are known as regions. Chile is organised around 15 regions, 54 provinces and 346 municipalities - see here.\nLet’s stop here and understand the spatial data frame or sf object we are reading. We can see it has 56 features (i.e. rows) and 5 fields (columns) within a bounding box which defines the area we can visualise on a map. You can see how the map of provinces below seems off to the right. That is because the bounding box has been set to include Chilean islands off of the coast of the country on the Pacific ocean. We will work on adjusting this at a later point in this session.\nThe line CRS or Coordinate Reference Systems identifies the projection system currently attached to the data. This would be the CRS that will be used if we decided to map the data. The component is incredible important if you intend to combine information from two spatial data frames. Ensure they are on the same CRS! A good idea is to used planar projection systems. Lovelace, Nowosad, and Muenchow (2019) provide a good discussion on the various projection systems.\n\nshp_pro <- read_sf(\"./data/shp/adm/province/PROVINCIAS_2020.shp\") %>% \n  st_simplify(preserveTopology =T,\n              dTolerance = 1000) %>%  # 1km\n  sf::st_make_valid() \nshp_pro\n\nSimple feature collection with 56 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -109.4488 ymin: -55.98085 xmax: -66.42812 ymax: -17.4984\nGeodetic CRS:  SIRGAS-Chile 2002\n# A tibble: 56 × 6\n   CUT_REG CUT_PROV REGION        PROVINCIA SUPERFICIE                  geometry\n * <chr>   <chr>    <chr>         <chr>          <dbl>        <MULTIPOLYGON [°]>\n 1 08      081      Biobío        Concepci…      3469. (((-72.77092 -37.002, -7…\n 2 01      014      Tarapacá      Tamarugal     39428. (((-68.53576 -21.06468, …\n 3 04      042      Coquimbo      Choapa        10131. (((-70.55491 -31.50954, …\n 4 05      054      Valparaíso    Petorca        4589. (((-71.46609 -32.49606, …\n 5 10      101      Los Lagos     Llanquih…     14857. (((-73.06627 -41.89869, …\n 6 11      114      Aysén del Ge… General …     11758. (((-71.75146 -46.33864, …\n 7 05      057      Valparaíso    San Feli…      2636. (((-70.61116 -32.81214, …\n 8 12      121      Magallanes y… Magallan…     37193. (((-73.03711 -54.47267, …\n 9 13      136      Metropolitan… Talagante       581. (((-70.79251 -33.69482, …\n10 15      152      Arica y Pari… Parinaco…      8142. (((-68.91415 -18.89034, …\n# ℹ 46 more rows\n\n\n\n\n\n\n\nWe will also use the regional boundaries for visualisation purposes. For now, we will just read them.\n\nshp_reg <- read_sf(\"./data/shp/adm/region/REGIONES_2020.shp\") %>% \n  st_simplify(preserveTopology =T,\n              dTolerance = 1000) %>%  # 1km\n  sf::st_make_valid()"
  },
  {
    "objectID": "spatial-patterns.html#spatial-indicators-of-human-mobility",
    "href": "spatial-patterns.html#spatial-indicators-of-human-mobility",
    "title": "3  Spatial patterns",
    "section": "3.4 Spatial indicators of human mobility",
    "text": "3.4 Spatial indicators of human mobility\nThis section focuses on computing various spatial indicators to analyse the patterns of human mobility. A key message to get across here is that digital footprint data do not capture the entire population living and moving in the country. We can capture signals or systematic trends, but there will be considerable amount of fluctuation of volatility. Such volatiblity may partly reflect the short-term variability in the patterns of human mobility and may also echo noise in the way in which the data are capture or process. Hence, we recommend to use indices and these indices should comprise aggregations of data in meaningful ways, based on geographical or temporal units.\n\n3.4.1 Origin-based indicators\nWe start by computing indicators from the perspective of origin areas. We generate a set of five indicators capturing average and cumulative patterns at the monthly level. We compute the following indicators:\n\nmean_perchange: is the average percent change in the count of movements from a given origin in relation to the baseline period over a month. It is computed as the average of the ratio of the number of movements from an area at time period t, minus the number of movements from an area during the baseline pre-pandemic period over the number of pmovements from an area during the baseline period.\nmean_diff_flow: is the difference in the count of movements from a given origin in relation to the baseline period over a month. It is computed as the difference between the number of movements from an area at time period t, minus the number of movements from an area during the baseline pre-pandemic period.\nsum_diff_flow: is the sum of the difference in the count of movements from a given origin in relation to the baseline period. It is computed as the sum of the difference between the number of movements from an area at time period t, minus the number of movements from an area during the baseline pre-pandemic period.\nmean_outflow: is the average count of movements from a given origin at a give time period over a month.\nsum_outflow: is the sum of the count of movements from a given origin at a give time period over a month.\n\n\norigin_df <- df20 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(start_polygon_name) %>% \n  dplyr::summarise(\n    mean_perchange = mean(percent_change, na.rm = T),\n    mean_diff_flow = mean(n_difference, na.rm = T),\n    sum_diff_flow = sum(n_difference, na.rm = T),\n    mean_outflow = mean(n_crisis, na.rm = T),\n    sum_outflow = sum(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\ntail(origin_df, 10)\n\n# A tibble: 10 × 6\n   start_polygon_name mean_perchange mean_diff_flow sum_diff_flow mean_outflow\n   <chr>                       <dbl>          <dbl>         <dbl>        <dbl>\n 1 Santiago                   -70.6         -792.      -1309523.         612. \n 2 Talagante                  -33.8         -263.       -127657.         269. \n 3 Talca                      -52.4         -150.        -70768          115. \n 4 Tamarugal                   24.0          -53.0        -7261.          90.8\n 5 Tierra del Fuego           -76.7          -19.8         -119.          12.2\n 6 Tocopilla                  147.            -4.23        -702.          38.5\n 7 Valdivia                   -75.8         -234.        -65400.          48.3\n 8 Valparaíso                 -62.3         -350.       -257762.         169. \n 9 Ñuble                      -62.5         -165.        -56482.          60.4\n10 Última Esperanza             1.77         -21.4          -21.4         10  \n# ℹ 1 more variable: sum_outflow <dbl>\n\n\nWe observe the observations at the tail of the data frame. We observe that Santiago recorded an average reduction of over 70% in the count of movements from Santiago in April 2020, in relation to the baseline. Yet, the average size of this reduction in outflows seems to have been relatively small, involving 792 and reporting an average outflow of 612 movements.\n\n\n\n\n\n\nQuestion 1\n\n\n\nAnalyse the origin-based indicators and interpret the patterns displayed for Valparaíso.\n\n\n\n\n3.4.2 Destination-based indicators\nMobility involves the spatial interaction between two areas. Mobility impacts both areas of origins and destinations (Rowe, Lovelace, and Dennett 2022). We often seek to understand both perspectives. Here we compute similar indicators to those calculated for the areas of origins. What interesting patterns can you see?\n\n\n\n\n\n\nQuestion 2\n\n\n\nAnalyse the designation-based indicators and interpret the patterns displayed for Santiago.\n\n\n\ndestination_df <- df20 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(end_polygon_name) %>% \n  dplyr::summarise(\n    mean_perchange = mean(percent_change, na.rm = T),\n    mean_diff_flow = mean(n_difference, na.rm = T),\n    sum_diff_flow = sum(n_difference, na.rm = T),\n    mean_inflow = mean(n_crisis, na.rm = T),\n    sum_inflow = sum(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\ntail(destination_df, 10)\n\n# A tibble: 10 × 6\n   end_polygon_name mean_perchange mean_diff_flow sum_diff_flow mean_inflow\n   <chr>                     <dbl>          <dbl>         <dbl>       <dbl>\n 1 Santiago                  -72.1       -850.        -1336029.       639. \n 2 Talagante                 -30.3       -266.         -128140        273. \n 3 Talca                     -52.1       -147.          -68827        117. \n 4 Tamarugal                  30.0        -49.4          -7360.        88.9\n 5 Tierra del Fuego          -68.3        -16             -112         13.1\n 6 Tocopilla                  63.3         -0.899         -165.        36.6\n 7 Valdivia                  -71.2       -230.          -63284.        48.2\n 8 Valparaíso                -66.2       -341.         -245913.       170. \n 9 Ñuble                     -63.1       -158.          -57870.        58.0\n10 Última Esperanza          -12.8        NaN                0        NaN  \n# ℹ 1 more variable: sum_inflow <dbl>\n\n\n\n\n3.4.3 Intraflows\nMeta-Facebook mobility data also allow us to capture short-distance, local movements occurring within areas. Below we compute indicators to measure the extent of movement within Chilean provinces, adopting similar indices to those described above.\nA key pattern is an increase in the number of movements within provinces in April 2020. This is likely to have been in response to COVID-19 restrictions constraining the amount of movement over long distances. If people moved, they mostly moved locally to go shopping, parks or for short walks. Yet, we also observe that some provinces report a decline.\n\n\n\n\n\n\nQuestion 3\n\n\n\nWhy do you think those areas experienced a decline in local mobility in April 2020?\n\n\n\norigin_df <- df20 %>% \n  filter(start_polygon_name == end_polygon_name) %>% \n  group_by(start_polygon_name) %>% \n  dplyr::summarise(\n    mean_perchange = mean(percent_change, na.rm = T),\n    mean_diff_flow = mean(n_difference, na.rm = T),\n    sum_diff_flow = sum(n_difference, na.rm = T),\n    mean_intraflow = mean(n_crisis, na.rm = T),\n    sum_intraflow = sum(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\ntail(origin_df, 10)\n\n# A tibble: 10 × 6\n   start_polygon_name mean_perchange mean_diff_flow sum_diff_flow mean_intraflow\n   <chr>                       <dbl>          <dbl>         <dbl>          <dbl>\n 1 Santiago                    6.00         32253.       2902809.        585443 \n 2 Talagante                  24.0           3776.        339841.         19627.\n 3 Talca                       4.48          1479.        133093.         34622.\n 4 Tamarugal                 -15.4           -612.        -55063.          3342.\n 5 Tierra del Fuego            1.62            13.6         1228.           886.\n 6 Tocopilla                  14.5            121.         10931            976.\n 7 Valdivia                  -10.6          -2895.       -260512.         24506.\n 8 Valparaíso                 -1.27         -1295.       -116524.        101255.\n 9 Ñuble                      -0.441         -158.        -14207.         36391.\n10 Última Esperanza          -18.7           -164.        -14750.           712.\n# ℹ 1 more variable: sum_intraflow <dbl>\n\n\n\n\n3.4.4 Netflows\nAn additional key dimension of mobility is its net balance; that is, the extent to which human mobility acts to redistribute population across areas of the country. While some areas report population gains, other experience decline.\nDuring the early stages of COVID-19, photo evidence of empty cities around the world poured over the Internet. Anecdotal evidence suggested the occurrence of an urban exodus, particularly from large cities as people sought more and greener spaces (see some our work on COVID and mobility, e.g. Rowe et al. 2022). At the same time, they sought to avoid high density areas, and they realised the need for bigger housing areas as they become multi-functional spaces for work, study and leisure for entire family units. People were said to have moved to sparsely populated rural areas, suburban spaces and more attractive migration destinations.\nBelow we compute a measure of the net balance of mobility flows between areas of origin and destination. We use the average number of movements into an areas, minus the number of movements out of that area. We have a look at the head of the data frame and observe that the average net mobility balance is virtually zero. However, at this point, we should recognise that while indicators are useful to measure different dimensions of human mobility, data visualisations are key to identify systematic patterns in the data.\n\n# mean outflow by area\noutflows_df <- df20 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(start_polygon_name) %>% \n  dplyr::summarise(\n    mean_outflow = mean(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\n# mean inflow by area\ninflows_df <- df20 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(end_polygon_name) %>% \n  dplyr::summarise(\n    mean_inflow = mean(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\n# combine data frames\nnetflow_df <- cbind(inflows_df, outflows_df)\n\n# mean netflow by area\nnetflow_df <- netflow_df %>% \n  mutate(\n    mean_netflow = mean_inflow - mean_outflow\n  ) %>% \n  select(start_polygon_name, end_polygon_name, mean_inflow, mean_outflow, mean_netflow)\n\nhead(netflow_df)\n\n  start_polygon_name end_polygon_name mean_inflow mean_outflow mean_netflow\n1        Antofagasta      Antofagasta    63.27513     66.00571    -2.730582\n2             Arauco           Arauco    91.14286     93.48276    -2.339901\n3              Arica            Arica    17.44444     20.16379    -2.719349\n4              Aysen            Aysen    28.47297     27.15385     1.319127\n5            Bío-Bío          Bío-Bío    77.86880     79.00000    -1.131195\n6          Cachapoal        Cachapoal   110.54008    112.71988    -2.179800\n\n\nGenerally a useful graphical representation of the data is histograms or kernel density histograms. They are helpful to easily have an understanding of the distribution of mobility indicators. The histogram below reveals that while most areas report an average net mobility balance of zero, some areas display losses or gains of over 10 or 20 movements, respectively.\n\n\n\n\n\n\nNote\n\n\n\nggplot is a primary tool for data visualisation in R. ggplot has a basic structure of three components:\n\nThe data: ggplot( data = data frame)\nGeometries: geom_xxx( . )\nAesthetic mapping: aes(x=variable, y=variable)\n\nThen you can work on the cosmetics of the figure such as changing the theme, axis, labels, etc.\n\n\n\nggplot(data = netflow_df) + # input the data\n  geom_density(aes(x = mean_netflow), # specify type of geom and aesthetics\n               alpha=0.5, \n               colour=\"darkblue\", \n               linewidth = 2\n               ) +\n  theme_tufte() + # choose the theme\n  theme(axis.text.y = element_text(size = 12), # edit labels format\n        axis.text.x = element_text(size = 12),\n        axis.title=element_text(size=14)\n                    ) + \n  labs(y = \"Density\", # label axis\n       x = \"Average net movement count\")"
  },
  {
    "objectID": "spatial-patterns.html#mapping",
    "href": "spatial-patterns.html#mapping",
    "title": "3  Spatial patterns",
    "section": "3.5 Mapping",
    "text": "3.5 Mapping\nOnce you get a basic understanding of the data, you may want to have a more insightful representation of mobility indicators and add some context. Geospatial visualisations are great for these purposes, and for this end, cartography is key. A carefully crafted map can be an effective way of communicating complex information. Design issues include poor placement, size and readability of text and careless selection of colors. Have a look the style guide of the Journal of Maps for details, and also at the use of colours for effective communication. We recommend this piece by Crameri, Shephard, and Heron (2020) and Maceachren and Kraak (1997).\n\n\n\n\n\n\nQuestion 4\n\n\n\nWhy to create geovisualisations?\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor colour palettes, we recommend the following resources:\n\nthe R packages viridis and RColorBrewer\nthe website color brewer 2.0\na publication by Crameri, Shephard, and Heron (2020)\n\n\n\n\n3.5.1 Handling spatial data\nBut, before we get to map some data, there are some key elements we need to cover first. We will show you how to handle spatial data in R. As we indicated earlier in this section, sf is versatile R package to handle spatial data frames in R. A first key thing you need to know about spatial data is that they always have attached a CRS and ensuring there is a commonly shared CRS across your data is essential for mapping. We will be using a planar system, as opposed to a spherical system. We set our default CRS.\n\n# set crs\ncrs_default = \"EPSG:4326\"\n\nTo ensure you get a full understanding of the process of mapping, we will roll back and start from the beginning. We will re-read the data and re-compute the indicators, but this time we will convert our movement dataset into a spatial data frame by using the latitude and longitude of the origins as coordinates. This information will be used to convert our movement data frame into a spatial data frame using the latitude and longitude of the origins as geometry.\n\ndf20 <- readRDS(\"./data/fb/movement_adm/2020_04.rds\") %>% \n  mutate(GEOMETRY = NULL) %>% \n  dplyr::filter(country == \"CL\") %>% \n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), \n                                      crs = crs_default)\n\nglimpse(df20)\n\nRows: 29,491\nColumns: 18\n$ date_time                    <chr> \"2020-04-01 00:00\", \"2020-04-01 00:00\", \"…\n$ start_polygon_id             <chr> \"60845\", \"60862\", \"60845\", \"60862\", \"6086…\n$ start_polygon_name           <chr> \"Antofagasta\", \"Cardenal Caro\", \"Antofaga…\n$ end_polygon_id               <chr> \"60847\", \"60890\", \"60846\", \"60863\", \"6089…\n$ end_polygon_name             <chr> \"Tocopilla\", \"Melipilla\", \"El Loa\", \"Colc…\n$ length_km                    <dbl> 139.7543134, 24.0764953, 100.3339392, 24.…\n$ tile_size                    <dbl> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1…\n$ country                      <chr> \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\",…\n$ level                        <chr> \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"LEVEL3\", \"…\n$ n_crisis                     <dbl> 79, 18, 320, 71, NA, 369, NA, 20, 11, NA,…\n$ n_baseline                   <dbl> 59.50, 25.50, 671.00, 132.75, NA, 559.25,…\n$ n_difference                 <dbl> 19.50, -7.50, -351.00, -61.75, NA, -190.2…\n$ percent_change               <dbl> 32.231405, -28.301887, -52.232143, -46.16…\n$ is_statistically_significant <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ z_score                      <dbl> 2.0148470, -0.6837043, -4.0000000, -1.261…\n$ end_lat                      <dbl> -22.06894, -33.75413, -22.81611, -34.7036…\n$ end_lon                      <dbl> -69.60081, -71.19829, -68.20015, -71.0631…\n$ geometry                     <POINT [°]> POINT (-69.56718 -24.32798), POINT …\n\n\nWe will also re-read our province boundary data and ensure it is on the same CRS.\n\nshp_pro <- read_sf(\"./data/shp/adm/province/PROVINCIAS_2020.shp\") %>% \n  st_simplify(preserveTopology =T,\n              dTolerance = 1000) %>%  # 1km\n  sf::st_make_valid() %>% \n  st_transform(crs_default)\n\nOnce we have read our input data, we will re-compute a few of mobility indicators.\n\n# mean outflow by area\noutflows_df <- df20 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(start_polygon_name) %>% \n  dplyr::summarise(\n    mean_outflow = mean(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\n# mean inflow by area\ninflows_df <- df20 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(end_polygon_name) %>% \n  dplyr::summarise(\n    mean_inflow = mean(n_crisis, na.rm = T)\n    ) %>% \n  ungroup() %>% \n  st_drop_geometry()\n\n# combine data frames\nnetflow_df <- cbind(outflows_df, inflows_df)\n\n# mean netflow by area\nnetflow_df <- netflow_df %>% \n  mutate(\n    mean_netflow = mean_inflow - mean_outflow\n  ) %>% \n  dplyr::select(start_polygon_name, mean_inflow, mean_outflow, mean_netflow, geometry) %>% \n  rename(\n    polygon_name = start_polygon_name\n  ) \n\nhead(netflow_df)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -73.58022 ymin: -45.45868 xmax: -69.56718 ymax: -18.71308\nGeodetic CRS:  WGS 84\n  polygon_name mean_inflow mean_outflow mean_netflow\n1  Antofagasta    63.27513     66.00571    -2.730582\n2       Arauco    91.14286     93.48276    -2.339901\n3        Arica    17.44444     20.16379    -2.719349\n4        Aysen    28.47297     27.15385     1.319127\n5      Bío-Bío    77.86880     79.00000    -1.131195\n6    Cachapoal   110.54008    112.71988    -2.179800\n                     geometry\n1 POINT (-69.56718 -24.32798)\n2  POINT (-73.3454 -37.72772)\n3 POINT (-69.85541 -18.71308)\n4 POINT (-73.58022 -45.45868)\n5 POINT (-71.92786 -37.53828)\n6  POINT (-70.7088 -34.28421)\n\n\nNow let’s start mapping our data. Let’s do this by stage so you understand the key building blocks of this process. We first drawn the polygons representing the provinces of Chile.\n\np <- ggplot() + \n  geom_sf(data = shp_pro,\n          color = \"gray60\", \n          size = 0.1)\nlast_plot()\n\n\n\n\nLet’s add the centroids of the origins based on our movement data.\n\np <- p +\n  geom_point(data = netflow_df,\n    aes(geometry = geometry),\n    stat = \"sf_coordinates\"\n  ) \nlast_plot()\n\n\n\n\nThen we can remove the axes or background here:\n\np + theme_void()\n\n\n\n\nThe map is placed towards the right. We can centre the map by adjusting the bounding box of the shapefile. We can do this by obtaining the current bounding box and adjusting the x left limit.\n\nbbox_new <- st_bbox(shp_pro) # current bounding box\n\nxrange <- bbox_new$xmax - bbox_new$xmin # range of x values\nyrange <- bbox_new$ymax - bbox_new$ymin # range of y values\n\nbbox_new[1] <- bbox_new[1] + (0.6 * xrange) # xmin - left\n#bbox_new[3] <- bbox_new[3] + (0.5 * xrange) # xmax - right\n#bbox_new[2] <- bbox_new[2] - (0.5 * yrange) # ymin - bottom\n#bbox_new[4] <- bbox_new[4] + (0.5 * yrange) # ymax - top\n\nbbox_new <- bbox_new %>%  # take the bounding box ...\n  st_as_sfc() # ... and make it a sf polygon\n\nggplot() + \n  geom_sf(data = shp_pro,\n          color = \"gray60\", \n          size = 0.1) +\n  geom_point(data = netflow_df,\n    aes(geometry = geometry),\n    stat = \"sf_coordinates\",\n    size = .1\n  ) +\n  coord_sf(xlim = st_coordinates(bbox_new)[c(1,2),1], # min & max of x values\n           ylim = st_coordinates(bbox_new)[c(2,3),2]) + # min & max of y values\n  theme_void()\n\n\n\n\nSomething to note at this point is that two of the centroids lie outside the provincial polygons. This is difficult to visualise from the current map. We will find out this in a different way. We run a spatial join of the provincial polygons and our movement data frame, and check the provinces which were not matched. Below we can observe the result of this process. The provinces of Magallanes and Valparaíso were unmatched. That is because their centroids lie outside the polygon area. In the case of Valparaiso, islands attached to this province force the centroid to be position on the Pacific. In the case of Magallanes, the unusual shape of the province surrounded by fjords forces the centroid to be on the Pacific as well.\n\n# spatial join\nmob_indicators <- st_join(shp_pro, netflow_df)\n# check if all polygons are matched\nnetflow_df$check <- netflow_df$polygon_name %in% mob_indicators$polygon_name\n# identify unmatched polygons\nnetflow_df %>% select(polygon_name, check) %>% \n  filter(check == \"FALSE\")\n\nSimple feature collection with 2 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -71.75919 ymin: -53.0857 xmax: -71.70694 ymax: -33.14564\nGeodetic CRS:  WGS 84\n  polygon_name check                    geometry\n1   Magallanes FALSE  POINT (-71.70694 -53.0857)\n2   Valparaíso FALSE POINT (-71.75919 -33.14564)\n\n\nWe therefore adjust these centriods and force them to be within the polygons of provinces.\n\n# get coordinates\ncoordinates <- st_coordinates(netflow_df) \n# combine data frames\nnetflow_df <- cbind(netflow_df, coordinates) %>% \n  rename(\n    long = X, \n    lat = Y\n  )\n# list province to be adjusted\nprovince_name <- c(\"Valparaíso\", \"Magallanes\")\n# adjust the centroid\nfor (area in 1:2) {\n  long <- netflow_df %>% \n    st_drop_geometry() %>% \n    dplyr::filter(polygon_name == province_name[area]) %>% \n    select(long) %>% \n    as.numeric()\n  \n  lat <- netflow_df %>% \n    st_drop_geometry() %>%\n    dplyr::filter(polygon_name == province_name[area]) %>% \n    select(lat) %>% \n    as.numeric()\n\n  st_geometry(netflow_df[netflow_df$polygon_name == province_name[area], ]) <-  st_sfc(st_point(c( long * 0.98, lat * 1 )))\n}\n\nWe re-join the polygon boundary data and our movement data frame and check the results. We can now see that all spatial units were matched.\n\nmob_indicators <- st_join(shp_pro, netflow_df, \n                          st_intersects)\n\nnetflow_df$check <- netflow_df$polygon_name %in% mob_indicators$polygon_name\n\nnetflow_df %>% select(polygon_name, check) %>% \n  filter(check == \"FALSE\")\n\nSimple feature collection with 0 features and 2 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n[1] polygon_name check        geometry    \n<0 rows> (or 0-length row.names)\n\n\nSo far, we have only wrangled the data so we can start out mapping and spatial analysis.\n\n\n3.5.2 Choropleths\nWe first try choropleths. Choropleths are thematic maps. They are easy to create but also to get wrong. We will look at a set of the principles you can follow to create effective choropleth maps. Here three more questions to consider:\n\nWhat is being plotted?\nWhat is the target audience?\nWhat degree of interactivity we want to offer?\n\nWe will create maps of netflows, inflows and outflows. We will divide the data into categories. Categorising the data often facilites the identification of spatial patterns. There are different forms of organising these categories using quantiles, natural break points or more sophisticated clustering approaches. We will keep this simple and use seven categories. Feel free to explore the impacts on the map as these categories change.\n\n# set categories\nmob_indicators <- mob_indicators %>% \n  mutate(\n    netflow_class = mean_netflow %>% cut(7, dig.lab = 3),\n    inflow_class = mean_inflow %>% cut(7, dig.lab = 3),\n    outflow_class = mean_outflow %>% cut(7, dig.lab = 3)\n  ) \n\n# adjust labels for netflows\nnetflow_labels <- levels(mob_indicators$netflow_class)\nnetflow_labels <- gsub(\"\\\\(|\\\\]\", \"\", netflow_labels)\nlevels(mob_indicators$netflow_class) <- netflow_labels\n\n# adjust labels for inflows\ninflow_labels <- levels(mob_indicators$inflow_class)\ninflow_labels <- gsub(\"\\\\(|\\\\]\", \"\", inflow_labels)\nlevels(mob_indicators$inflow_class) <- inflow_labels\n\n# adjust labels for netflows\noutflow_labels <- levels(mob_indicators$outflow_class)\noutflow_labels <- gsub(\"\\\\(|\\\\]\", \"\", outflow_labels)\nlevels(mob_indicators$outflow_class) <- outflow_labels\n\n# change geometry\nshp_reg <- shp_reg %>% st_transform(crs_default)\n\nBelow we use ggplot to create our maps.\n\n# map netflows\nnetflow_plot <- ggplot(data = mob_indicators, aes(fill = netflow_class)) +\n  geom_sf(col = \"white\", size = .1) +\n  coord_sf() +\n  scale_fill_brewer(palette = \"RdBu\", direction = -1) +\n  scale_color_manual(labels = netflow_labels) +\n  theme_map() +\n  theme(plot.title = element_text(size = 22, face = \"bold\"),\n        legend.position = \"none\") +\n  labs(title = \"(a) Netflow\",\n       fill = \"Net count of moves\") +\n  theme_void() + \n  geom_sf(data = shp_reg,\n          col = \"grey70\", \n          size = .5,\n          fill = \"transparent\") +\n  coord_sf(xlim = st_coordinates(bbox_new)[c(1,2),1], \n           ylim = st_coordinates(bbox_new)[c(2,3),2]) \n\n# map inflows\ninflow_plot <- ggplot(data = mob_indicators, aes(fill = inflow_class)) +\n  geom_sf(col = \"white\", size = .1) +\n  coord_sf() +\n  scale_fill_brewer(palette = \"PuRd\", direction = 1) +\n  theme_map() +\n  theme(plot.title = element_text(size = 22, face = \"bold\"),\n        legend.position = \"none\") +\n  labs(title = \"(b) Inflow\",\n       fill = \"Count of moves\") +\n  theme_void() + \n  geom_sf(data = shp_reg,\n          col = \"grey70\", \n          size = .5,\n          fill = \"transparent\") +\n  coord_sf(xlim = st_coordinates(bbox_new)[c(1,2),1], \n           ylim = st_coordinates(bbox_new)[c(2,3),2]) \n\n# map outflows\noutflow_plot <- ggplot(data = mob_indicators, aes(fill = outflow_class)) +\n  geom_sf(col = \"white\", size = .1) +\n  coord_sf() +\n  scale_fill_brewer(palette = \"PuBu\", direction = 1) +\n  theme_map() +\n  theme(plot.title = element_text(size = 22, face = \"bold\"),\n        legend.position = \"none\") +\n  labs(title = \"(b) Outflow\",\n       fill = \"Count of moves\") +\n  theme_void() +\n    geom_sf(data = shp_reg,\n          col = \"grey70\", \n          size = .5,\n          fill = \"transparent\") +\n  coord_sf(xlim = st_coordinates(bbox_new)[c(1,2),1], \n           ylim = st_coordinates(bbox_new)[c(2,3),2]) \n\n# combine plots\nnetflow_plot + inflow_plot + outflow_plot\n\n\n\n\nThe maps display the average count of movement across provinces in Chile. In relative terms, they indicate that some of central provinces experienced larger losses compared to northern and southern provinces. Central provinces also display the largest average counts of movement. This is expected as these areas concentrate most of the Chilean population, and larger population centres are expected to generate more movement.\nFlow to Facebook population size\nWhen using digital footprint data, a key concern is whether the data are biased or representative of the local populations (Rowe 2023). In the context of mobility, for instance, we would expect that we would observe more movement where we observe a larger number of Meta-Facebook active users. To explore this, we could analyse the ratio of movement over the number of Meta-Facebook active users by area. High spatial variability in this ratio would be evidence of biases in the Meta-Facebook data capturing mobility. We compute the average number of outflow movement over the average Meta-Facebook active user population by province. The results are quite revealing, showing remarkable little variation across provinces. This suggests very little evidence of biases in the Meta-Facebook data to capture mobility. Of course, this evidence only applies for Chile. But this analysis could be easily implemented on data for other countries.\n\n# compute mean population\nmean_fb_pop <- pop20_df %>% group_by(polygon_name) %>% \n  dplyr::summarise(\n    mean_pop = mean(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\n# join to mobility indicators data frame\nmob_indicators <- left_join(mob_indicators, mean_fb_pop, \n                        by = c(\"polygon_name\" = \"polygon_name\")) %>% \n  mutate(\n    outflow_to_pop = (mean_outflow / mean_pop) # compute outflow to population\n  )\n\n# map outflow_to_pop\nggplot(data = mob_indicators, aes(fill = outflow_to_pop)) +\n  geom_sf(col = \"white\", size = .1) +\n  coord_sf() +\n  scale_fill_viridis_c() +\n  theme_map() +\n  theme(plot.title = element_text(size = 22, face = \"bold\"),\n        legend.position = \"none\") +\n  labs(title = \"Flows to population size\",\n       fill = \"Number of movements per 100\") +\n  theme_void() +\n    geom_sf(data = shp_reg,\n          col = \"grey70\", \n          size = .1,\n          fill = \"transparent\") +\n  coord_sf(xlim = st_coordinates(bbox_new)[c(1,2),1], \n           ylim = st_coordinates(bbox_new)[c(2,3),2])\n\n\n\n\nChanges over time\nMaps are also an effective way of analysing spatial patterns over time. Below we show us how you can analyse the average count of net movement for April 2020 and April 2022 using ggplot. Different from the maps above, here we use a continous scale to map the data. We can see slight variations in the net balance of movement.\n\n\n\n\n\n\nQuestion 5\n\n\n\nWhat interesting patterns do you see?\n\n\n\n# read April 2022 data\ndf22 <- readRDS(\"./data/fb/movement_adm/2022_04.rds\") %>% \n  mutate(GEOMETRY = NULL) %>% \n  dplyr::filter(country == \"CL\") %>% \n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), \n                                      crs = crs_default)\n\n# mean outflow by area\noutflows_df <- df22 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(start_polygon_name) %>% \n  dplyr::summarise(\n    mean_outflow = mean(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\n# mean inflow by area\ninflows_df <- df22 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(end_polygon_name) %>% \n  dplyr::summarise(\n    mean_inflow = mean(n_crisis, na.rm = T)\n    ) %>% \n  ungroup() %>% \n  st_drop_geometry()\n\n# combine data frames\nnetflow_df <- cbind(outflows_df, inflows_df)\n\n# mean netflow by area\nnetflow_df <- netflow_df %>% \n  mutate(\n    mean_netflow = mean_inflow - mean_outflow\n  ) %>% \n  dplyr::select(start_polygon_name, mean_inflow, mean_outflow, mean_netflow, geometry) %>% \n  rename(\n    polygon_name = start_polygon_name\n  ) \n\n# extract coordinates\ncoordinates <- st_coordinates(netflow_df) \n\n# add coordinates\nnetflow_df <- cbind(netflow_df, coordinates) %>% \n  rename(\n    long = X, \n    lat = Y\n  )\n\n# list province names\nprovince_name <- c(\"Valparaíso\", \"Magallanes\")\n\n# loop to replace point geometries\nfor (area in 1:2) {\n  long <- netflow_df %>% \n    st_drop_geometry() %>% \n    dplyr::filter(polygon_name == province_name[area]) %>% \n    select(long) %>% \n    as.numeric()\n  \n  lat <- netflow_df %>% \n    st_drop_geometry() %>%\n    dplyr::filter(polygon_name == province_name[area]) %>% \n    select(lat) %>% \n    as.numeric()\n\n  st_geometry(netflow_df[netflow_df$polygon_name == province_name[area], ]) <-  st_sfc(st_point(c( long * 0.98, lat * 1 )))\n}\n\n# combine indicators with province polygons\nmob_indicators22 <- st_join(shp_pro, netflow_df, \n                          st_intersects)\n\n# add year to data frame\nmob_indicators$year <- \"2020\"\nmob_indicators22$year <- \"2022\"\n\n# combine data frames for 2020 and 2022\nmob_indicators <- mob_indicators %>% select(names(mob_indicators22)) # remove columns to make data frames compatible\nmob_indicators_20.22 <- rbind(mob_indicators, mob_indicators22)\n\n\n\n\n\n\n\nNote\n\n\n\nWe note that facet_grid(.) is a useful function to know if you intend to produce figures by layers and these layers are defined by a different variable / column in your data frame. In our example, this is year.\n\n\n\n# map netflows\nggplot(data = mob_indicators_20.22, aes(fill = mean_netflow)) +\n  geom_sf(col = \"white\", size = .1) +\n  coord_sf() +\n  scale_fill_gradient2(\n    low = muted(\"blue\"),\n    mid = \"white\",\n    high = \"red\",\n    midpoint = 0,\n    space = \"Lab\",\n    na.value = \"white\",\n    guide = \"colourbar\",\n    aesthetics = \"fill\"\n    ) +\n  theme_map() +\n  facet_grid(cols = vars(year)) +\n  theme(plot.title = element_text(size = 22, face = \"bold\"),\n        legend.position = \"none\") +\n  labs(title = \"Netflow\",\n       fill = \"Number of movements\") +\n  theme_void() + \n  geom_sf(data = shp_reg,\n          col = \"grey70\", \n          size = .5,\n          fill = \"transparent\") +\n  coord_sf(xlim = st_coordinates(bbox_new)[c(1,2),1], \n           ylim = st_coordinates(bbox_new)[c(2,3),2]) \n\n\n\n\n\n\n3.5.3 Interactive mapping\nAn alternative way to analyse the data is using interactive maps. Interactive maps provide greater flexibility to explore the data by adding a base map for greater context. We use tmap for this task. tmap is a great package for mapping and you should probably add it to your toolbox if you are working on geographic information systems using R.\nWe map the average net count of movement for April 2022. We first enable interactivity by running tmap_mode(\"view\") and then create the map. Using the menu on the left top of the map below, we can zoom in and out to explore the map and also change the base layer. We can also display or hide the colouring layers of our indicator. This allows to see the names of the areas experiencing net gains and losses of moves.\n\n# create a map\ntmap_mode(\"view\") # enable interactivity\ntm_shape(mob_indicators22) + # input data\n    tm_fill(\"mean_netflow\", # draw and fill polygons\n          palette = \"RdBu\",\n          title = \"Netflows\")\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe use ttm() to switch off the interactive functionality of tmap.\n\n\n\n# switch to other mode: \"view\"\nttm()\n\ntmap mode set to plotting\n\n\n\n\n3.5.4 Flow mapping\nAn additional key dimension of the analysis of origin-destination flow data is visually understanding the relationship between origins and destinations. This helps understanding the extent of interaction of individual areas with the rest of the country, and also informs how changes in a specific area may impact others - see for example Rowe and Patias (2020) and Rowe (2022). Flow maps are often used to visualise the complex network of mobility flows between areas. A recently developed tool for this end is mapbox. If you want to use mapbox you need to sign up. You can create an account for free to use some basic products. We can use mapbox through the mapdeck package in R.\nSo you have a start-to-end understanding of the process, we will begin from loading the input movement data. We compute the average count by origin-destination pair for April 2020, and prepare a data frame containing origin and destination coordinates.\n\n# read data\ndf20 <- readRDS(\"./data/fb/movement_adm/2020_04.rds\") %>% \n  mutate(GEOMETRY = NULL) %>% \n  dplyr::filter(country == \"CL\") \n\n# compute mean move by origin-destination pair\nflow_df20 <- df20 %>% \n  filter(start_polygon_name != end_polygon_name) %>% \n  group_by(start_polygon_name, end_polygon_name) %>% \n  dplyr::summarise(\n    mean_flow = mean(n_crisis, na.rm = T)\n    ) %>% \n  ungroup()\n\n# create a coordinate data frame for origins\norigin_coordinate_df <- df20 %>% \n  dplyr::select( c(start_polygon_name, start_lat, start_lon)) %>% \n  distinct()\n\n# create a coordinate data frame for destinations\ndestination_coordinate_df <- df20 %>% \n  dplyr::select( c(end_polygon_name, end_lat, end_lon)) %>% \n  distinct()\n\n# join coordinates for origins and destinations\nflow_df20 <- left_join(flow_df20, origin_coordinate_df, by = c(\"start_polygon_name\" = \"start_polygon_name\"))\nflow_df20 <- left_join(flow_df20, destination_coordinate_df, by = c(\"end_polygon_name\" = \"end_polygon_name\"))\n\nFor our illustration, we will focus on the province of Santiago.\n\ndf_santiago <- flow_df20 %>% dplyr::filter(start_polygon_name == \"Santiago\")\n\nhead(df_santiago)\n\n# A tibble: 6 × 7\n  start_polygon_name end_polygon_name mean_flow start_lat start_lon end_lat\n  <chr>              <chr>                <dbl>     <dbl>     <dbl>   <dbl>\n1 Santiago           Antofagasta           33.3     -33.4     -70.5   -24.3\n2 Santiago           Arauco               NaN       -33.4     -70.5   -37.7\n3 Santiago           Arica                 17.8     -33.4     -70.5   -18.7\n4 Santiago           Bío-Bío               18.5     -33.4     -70.5   -37.5\n5 Santiago           Cachapoal            292.      -33.4     -70.5   -34.3\n6 Santiago           Cardenal Caro         13.3     -33.4     -70.5   -34.3\n# ℹ 1 more variable: end_lon <dbl>\n\n\n\n\n\nTo use mapbox, you will need to sign up for an account on the mapbox website. For this workshop, we have generated a key to share but we strongly suggest to create an account as the key will last for a certain period of time. The map generated is interactive. If you can explore it by clicking on it and moving your mouse. If you can also zoom in and out by double-clicking.\nA striking pattern of the map below is the high degree of connectivity of Santiago with the rest of the country. Flows from Santiago not only extend to proximate and adjacent provinces but extend to far provinces in the north and south of the country.\n\nkey <- my_key ## put your own token here\n\nflowmap <- mapdeck( token = key, style = mapdeck_style(\"dark\"),\n                location = c(-3.7, 40.4), zoom = 6, pitch = 45) %>%\n  add_arc(\n    data = df_santiago,\n    layer_id = \"arc_layer\",\n    origin = c(\"start_lon\", \"start_lat\"),\n    destination = c(\"end_lon\", \"end_lat\"),\n    # stroke_from = \"start_polygon_name\",\n    # stroke_to = \"end_polygon_name\",\n    # stroke_width = \"stroke\",\n    palette = \"reds\",\n    legend = list( stroke_from = F, stroke_to = F ),\n  )\n\n# plot the interactive map\nflowmap\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\n\n\n\nCreate a flow map for your province of interest.\n\n\n\n\n\n\nAppelhans, Tim, Florian Detsch, Christoph Reudenbach, and Stefan Woellauer. 2022. Mapview: Interactive Viewing of Spatial Data in r. https://github.com/r-spatial/mapview.\n\n\nBaddeley, Adrian, Ege Rubak, and Rolf Turner. 2015. Spatial Point Patterns: Methodology and Applications with r. CRC press.\n\n\nBaddeley, Adrian, Rolf Turner, and Ege Rubak. 2022. Spatstat: Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests. http://spatstat.org/.\n\n\nBivand, Roger. 2022. Spdep: Spatial Dependence: Weighting Schemes, Statistics.\n\n\nBivand, Roger, and Gianfranco Piras. 2022. Spatialreg: Spatial Regression Analysis. https://CRAN.R-project.org/package=spatialreg.\n\n\nCrameri, Fabio, Grace E. Shephard, and Philip J. Heron. 2020. “The Misuse of Colour in Science Communication.” Nature Communications 11 (1). https://doi.org/10.1038/s41467-020-19160-7.\n\n\nDunnington, Dewey, Edzer Pebesma, and Ege Rubak. 2023. S2: Spherical Geometry Operators Using the S2 Geometry Library. https://CRAN.R-project.org/package=s2.\n\n\nGonzález-Leonardo, Miguel, Antonio López-Gay, Niall Newsham, Joaquín Recaño, and Francisco Rowe. 2022. “Understanding Patterns of Internal Migration During the COVID-19 Pandemic in Spain.” Population, Space and Place 28 (6). https://doi.org/10.1002/psp.2578.\n\n\nGonzález-Leonardo, Miguel, and Francisco Rowe. 2022. “Visualizing Internal and International Migration in the Spanish Provinces During the COVID-19 Pandemic.” Regional Studies, Regional Science 9 (1): 600–602. https://doi.org/10.1080/21681376.2022.2125824.\n\n\nGonzález-Leonardo, Miguel, Francisco Rowe, and Alberto Fresolone-Caparrós. 2022. “Rural Revival? The Rise in Internal Migration to Rural Areas During the COVID-19 Pandemic. Who Moved and Where?” Journal of Rural Studies 96 (December): 332–42. https://doi.org/10.1016/j.jrurstud.2022.11.006.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with r. CRC Press.\n\n\nMaceachren, Alan M., and Menno-Jan Kraak. 1997. “Exploratory Cartographic Visualization: Advancing the Agenda.” Computers & Geosciences 23 (4): 335–43. https://doi.org/10.1016/s0098-3004(97)00018-6.\n\n\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\n———. 2022a. Sf: Simple Features for r. https://CRAN.R-project.org/package=sf.\n\n\n———. 2022b. Stars: Spatiotemporal Arrays, Raster and Vector Data Cubes. https://CRAN.R-project.org/package=stars.\n\n\n———. 2023. Lwgeom: Bindings to Selected Liblwgeom Functions for Simple Features. https://github.com/r-spatial/lwgeom/.\n\n\nPebesma, Edzer J. 2004. “Multivariable Geostatistics in S: The Gstat Package.” Computers & Geosciences 30 (7): 683–91. https://doi.org/10.1016/j.cageo.2004.03.012.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in r. CRC Press.\n\n\nPebesma, Edzer, and Benedikt Graeler. 2022. Gstat: Spatial and Spatio-Temporal Geostatistical Modelling, Prediction and Simulation. https://github.com/r-spatial/gstat/.\n\n\nRowe, Francisco. 2022. “Using Digital Footprint Data to Monitor Human Mobility and Support Rapid Humanitarian Responses.” Regional Studies, Regional Science 9 (1): 665–68. https://doi.org/10.1080/21681376.2022.2135458.\n\n\n———. 2023. “Big Data.” In, 42–47. Edward Elgar Publishing. https://doi.org/10.4337/9781800883499.ch09.\n\n\nRowe, Francisco, Alessia Calafiore, Daniel Arribas-Bel, Krasen Samardzhiev, and Martin Fleischmann. 2022. “Urban Exodus? Understanding Human Mobility in Britain During the COVID-19 Pandemic Using Meta-Facebook Data.” Population, Space and Place 29 (1). https://doi.org/10.1002/psp.2637.\n\n\nRowe, Francisco, Miguel González-Leonardo, and Tony Champion. 2023. “Virtual Special Issue: Internal Migration in Times of COVID-19.” Population, Space and Place, March. https://doi.org/10.1002/psp.2652.\n\n\nRowe, Francisco, Robin Lovelace, and Adam Dennett. 2022. “Spatial Interaction Modelling: A Manifesto.” http://dx.doi.org/10.31219/osf.io/xcdms.\n\n\nRowe, Francisco, and Nikos Patias. 2020. “Mapping the Spatial Patterns of Internal Migration in Europe.” Regional Studies, Regional Science 7 (1): 390–93. https://doi.org/10.1080/21681376.2020.1811139.\n\n\nSchwartz, Joe et al. 2009. “Bing Maps Tile System.” Microsoft Developer Network Available: Http://Msdn. Microsoft. Com/En-Us/Library/Bb259689. Aspx.\n\n\nTennekes, Martijn. 2018. “tmap: Thematic Maps in R.” Journal of Statistical Software 84 (6): 1–39. https://doi.org/10.18637/jss.v084.i06.\n\n\n———. 2022. Tmap: Thematic Maps. https://github.com/r-tmap/tmap.\n\n\nWang, Yikang, Chen Zhong, Qili Gao, and Carmen Cabrera-Arnau. 2022. “Understanding Internal Migration in the UK Before and During the COVID-19 Pandemic Using Twitter Data.” Urban Informatics 1 (1). https://doi.org/10.1007/s44212-022-00018-w."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Appelhans, Tim, Florian Detsch, Christoph Reudenbach, and Stefan\nWoellauer. 2022. Mapview: Interactive Viewing of Spatial Data in\nr. https://github.com/r-spatial/mapview.\n\n\nBaddeley, Adrian, Ege Rubak, and Rolf Turner. 2015. Spatial Point\nPatterns: Methodology and Applications with r. CRC press.\n\n\nBaddeley, Adrian, Rolf Turner, and Ege Rubak. 2022. Spatstat:\nSpatial Point Pattern Analysis, Model-Fitting, Simulation, Tests.\nhttp://spatstat.org/.\n\n\nBivand, Roger. 2022. Spdep: Spatial Dependence: Weighting Schemes,\nStatistics.\n\n\nBivand, Roger, and Gianfranco Piras. 2022. Spatialreg: Spatial\nRegression Analysis. https://CRAN.R-project.org/package=spatialreg.\n\n\nCrameri, Fabio, Grace E. Shephard, and Philip J. Heron. 2020. “The\nMisuse of Colour in Science Communication.” Nature\nCommunications 11 (1). https://doi.org/10.1038/s41467-020-19160-7.\n\n\nDunnington, Dewey, Edzer Pebesma, and Ege Rubak. 2023. S2: Spherical\nGeometry Operators Using the S2 Geometry Library. https://CRAN.R-project.org/package=s2.\n\n\nGonzález-Leonardo, Miguel, Antonio López-Gay, Niall Newsham, Joaquín\nRecaño, and Francisco Rowe. 2022. “Understanding Patterns of\nInternal Migration During the COVID-19 Pandemic in\nSpain.” Population, Space and Place 28 (6). https://doi.org/10.1002/psp.2578.\n\n\nGonzález-Leonardo, Miguel, and Francisco Rowe. 2022. “Visualizing\nInternal and International Migration in the Spanish Provinces During the\nCOVID-19 Pandemic.” Regional Studies, Regional Science 9\n(1): 600–602. https://doi.org/10.1080/21681376.2022.2125824.\n\n\nGonzález-Leonardo, Miguel, Francisco Rowe, and Alberto\nFresolone-Caparrós. 2022. “Rural Revival? The Rise in Internal\nMigration to Rural Areas During the COVID-19 Pandemic. Who Moved and\nWhere?” Journal of Rural Studies 96 (December): 332–42.\nhttps://doi.org/10.1016/j.jrurstud.2022.11.006.\n\n\n“Learn about Your Location Privacy | Privacy Center | Manage Your\nPrivacy on Facebook, Instagram and Messenger | Facebook Privacy.”\nhttps://www.facebook.com/privacy/guide/location/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019.\nGeocomputation with r. CRC Press.\n\n\nMaas, Paige, Shankar Iyer, Andreas Gros, Wonhee Park, Laura McGorman,\nChaya Nayak, and P. Alex Dow. 2019. “Facebook Disaster Maps:\nAggregate Insights for Crisis Response & Recovery.” In\nProceedings of the 25th ACM SIGKDD International Conference on\nKnowledge Discovery & Data Mining, 3173. KDD ’19. New York, NY,\nUSA: Association for Computing Machinery. https://doi.org/10.1145/3292500.3340412.\n\n\nMaceachren, Alan M., and Menno-Jan Kraak. 1997. “Exploratory\nCartographic Visualization: Advancing the Agenda.” Computers\n& Geosciences 23 (4): 335–43. https://doi.org/10.1016/s0098-3004(97)00018-6.\n\n\nPebesma, Edzer. 2018. “Simple Features for R:\nStandardized Support for Spatial Vector Data.”\nThe R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\n———. 2022a. Sf: Simple Features for r. https://CRAN.R-project.org/package=sf.\n\n\n———. 2022b. Stars: Spatiotemporal Arrays, Raster and Vector Data\nCubes. https://CRAN.R-project.org/package=stars.\n\n\n———. 2023. Lwgeom: Bindings to Selected Liblwgeom Functions for\nSimple Features. https://github.com/r-spatial/lwgeom/.\n\n\nPebesma, Edzer J. 2004. “Multivariable Geostatistics in S: The\nGstat Package.” Computers & Geosciences 30 (7):\n683–91. https://doi.org/10.1016/j.cageo.2004.03.012.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With\nApplications in r. CRC Press.\n\n\nPebesma, Edzer, and Benedikt Graeler. 2022. Gstat: Spatial and\nSpatio-Temporal Geostatistical Modelling, Prediction and\nSimulation. https://github.com/r-spatial/gstat/.\n\n\nRowe, Francisco. 2022. “Using Digital Footprint Data to Monitor\nHuman Mobility and Support Rapid Humanitarian Responses.”\nRegional Studies, Regional Science 9 (1): 665–68. https://doi.org/10.1080/21681376.2022.2135458.\n\n\n———. 2023. “Big Data.” In, 42–47. Edward Elgar Publishing.\nhttps://doi.org/10.4337/9781800883499.ch09.\n\n\nRowe, Francisco, Carmen Cabrera-Arnau, and Elisabetta Piestrostefani.\n2023. Population Science. population-science.net.\n\n\nRowe, Francisco, Alessia Calafiore, Daniel Arribas-Bel, Krasen\nSamardzhiev, and Martin Fleischmann. 2022. “Urban Exodus?\nUnderstanding Human Mobility in Britain During the COVID-19\nPandemic Using Meta-Facebook Data.” Population,\nSpace and Place 29 (1). https://doi.org/10.1002/psp.2637.\n\n\nRowe, Francisco, Miguel González-Leonardo, and Tony Champion. 2023.\n“Virtual Special Issue: Internal Migration in Times of\nCOVID-19.” Population, Space and Place,\nMarch. https://doi.org/10.1002/psp.2652.\n\n\nRowe, Francisco, Robin Lovelace, and Adam Dennett. 2022. “Spatial\nInteraction Modelling: A Manifesto.” http://dx.doi.org/10.31219/osf.io/xcdms.\n\n\nRowe, Francisco, and Nikos Patias. 2020. “Mapping the Spatial\nPatterns of Internal Migration in Europe.” Regional Studies,\nRegional Science 7 (1): 390–93. https://doi.org/10.1080/21681376.2020.1811139.\n\n\nSchwartz, Joe et al. 2009. “Bing Maps Tile System.”\nMicrosoft Developer Network Available: Http://Msdn. Microsoft.\nCom/En-Us/Library/Bb259689. Aspx.\n\n\nTennekes, Martijn. 2018. “tmap:\nThematic Maps in R.” Journal of Statistical\nSoftware 84 (6): 1–39. https://doi.org/10.18637/jss.v084.i06.\n\n\n———. 2022. Tmap: Thematic Maps. https://github.com/r-tmap/tmap.\n\n\nWang, Yikang, Chen Zhong, Qili Gao, and Carmen Cabrera-Arnau. 2022.\n“Understanding Internal Migration in the UK Before and During the\nCOVID-19 Pandemic Using Twitter Data.” Urban Informatics\n1 (1). https://doi.org/10.1007/s44212-022-00018-w."
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Welcome",
    "section": "",
    "text": "This website hosts the materials for the workshop “Using Digital Footprint Data to Measure and Monitor Human Mobility”. This training workshop was designed and is delivered by Prof. Francisco Rowe, Dr. Carmen Cabrera-Arnau, Dr. Miguel González-Leonardo, Ruth Neville and Andrea Nasuto.\nThe website is free to use and is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International.\n\nContact\n\nProf. Francisco Rowe, Professor in Population Data Science\nf.rowe-gonzalez [at] liverpool.ac.uk\nDepartment of Geography and Planning, University of Liverpool, Liverpool, United Kingdom"
  },
  {
    "objectID": "overview.html#workshop-structure",
    "href": "overview.html#workshop-structure",
    "title": "1  Come prepared",
    "section": "1.1 Workshop structure",
    "text": "1.1 Workshop structure\n\n\n\n\n\n\n\nTime\nActivity\n\n\n\n\n15 min\nWelcome, introduction to workshop activities\n\n\n20 min\nDownloading the workshop materials from Github\n\n\n35 min\nImporting libraries, network theory basics\n\n\n10 min\nComfort break\n\n\n45 min\nThe African road network\n\n\n45 min\nExperiments and percolation\n\n\n10 min\nWrap-up"
  },
  {
    "objectID": "come-prepared.html#workshop-structure",
    "href": "come-prepared.html#workshop-structure",
    "title": "1  Come prepared",
    "section": "1.1 Workshop structure",
    "text": "1.1 Workshop structure\n\n\n\nTime\nActivity\n\n\n\n\n15 min\nWelcome, introduction to workshop activities\n\n\n20 min\nDownloading the workshop materials from Github\n\n\n35 min\nImporting libraries, network theory basics\n\n\n10 min\nComfort break\n\n\n45 min\nThe African road network\n\n\n45 min\nExperiments and percolation\n\n\n10 min\nWrap-up"
  },
  {
    "objectID": "come-prepared.html#before-the-workshop",
    "href": "come-prepared.html#before-the-workshop",
    "title": "1  Come prepared",
    "section": "1.2 Before the workshop",
    "text": "1.2 Before the workshop\n\n\n\n\n\n\nImportant\n\n\n\nPlease make sure you download and install the most recent version of R, RStudio and Quarto on the computer that you will be using during the workshop, and install the indicated R packages – see detailed instructions below.\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll three software packages are open and free to use.\n\n\nR\nYou can download R here. Make sure you select the appropriate version for your Operating System: Windows, MacOS (Apple silicon M1/M2 or older intel Macs). For example, if you use a macOS laptop with an M1 processor, click on ‘Download R for macOS’ and then, click the link to download the installer file (.pkg extension for macOS) under the header ‘For Apple silicon (M1/M2) Macs’. You can then open the installer and follow the instructions that you will be prompted with. For Windows users, click on ‘install R for the first time’ and follow the prompts.\nRStudio\nYou will also need to download RStudio Desktop (or simply RStudio), which is an integrated development environment to help you write code in R more easily. To download RStudio, follow this link and scroll down to the section titled ‘All Installers and Tarballs’. Download the appropriate installer file according to your Operating System. Then, open the installer and follow the installation instructions that you will be prompted with.\nQuarto\nDownload Quarto from this website. Quarto is a publishing system that will allow you to open and work on the computational notebooks for the workshop. On ‘Step 1’ on the website, download the version of Quarto that matches your Operating System. Open the installer file, run it and follow the prompts.\nR packages\nOnce you have installed R, you will need to install some R extensions, known as packages, that will be useful for the applications explored in this workshop. In this case, you only need to install one package:\n\nigraph\n\nTo install any package, open RStudio. On the console window (normally at the bottom left), write the following command: install.packages(\"name of package\"). Make sure you replace “name of package” by the actual name of the package that you want to install e.g. install.packages(\"tidyverse\"). Then, press enter and repeat this process until you have installed all the packages in the list.\nIf there are several packages you need to install (suppose you need to install tidyverse, ggthemes, igraph and dyplr), you can also install them all at once by copying and running the code below:\n\nlist.of.packages.cran &lt;- c(\n   \"tidyverse\",\n   \"ggthemes\",\n   \"igraph\",\n   \"dyplr\"\n)\n\nnew.packages.cran &lt;- list.of.packages.cran[!(list.of.packages.cran %in% installed.packages()[,\"Package\"])]\nif(length(new.packages.cran)) install.packages(new.packages.cran)\n\nfor(i in 1:length(list.of.packages.cran)) {\n  library(list.of.packages.cran[i], character.only = T)\n}\n\nOnce your packages are install, you will need to load them in order to be able to use it in your code. This can be done by copying and running the code below:\n\ndeps &lt;- list(\n   \"tidyverse\",\n   \"ggthemes\",\n   \"igraph\",\n   \"dyplr\"\n)\n\nfor(lib in deps){library(lib, character.only = TRUE)}\n\nBut as we mentioned, we only need igraph here, so you can install it simply using install.packages(\"igraph\") and once it is installed, you can load it simply running library(igraph).\n\n\n\n\n\n\nImportant\n\n\n\nFurther instructions on how to download the workshop material from Github will be given during the workshop."
  },
  {
    "objectID": "introduction-networks.html#dependencies",
    "href": "introduction-networks.html#dependencies",
    "title": "2  Introduction to the basics of network analysis",
    "section": "2.1 Dependencies",
    "text": "2.1 Dependencies"
  },
  {
    "objectID": "introduction-networks.html#creating-networks",
    "href": "introduction-networks.html#creating-networks",
    "title": "2  Introduction to the basics of network analysis",
    "section": "2.2 Creating networks",
    "text": "2.2 Creating networks\n\n2.2.1 Starting from the basics\n\n\n2.2.2 Adding attributes\n\n\n2.2.3 Basic visualisation"
  },
  {
    "objectID": "introduction-networks.html#network-metrics",
    "href": "introduction-networks.html#network-metrics",
    "title": "2  Introduction to the basics of network analysis",
    "section": "2.3 Network metrics",
    "text": "2.3 Network metrics\n\n2.3.1 Density\n\n\n2.3.2 Reciprocity\n\n\n2.3.3 Degree\n\n\n2.3.4 Distances\n\n\n2.3.5 Centrality\n\n\n2.3.6 Hubs and authorities"
  },
  {
    "objectID": "african-network.html#data",
    "href": "african-network.html#data",
    "title": "3  The African road network",
    "section": "3.2 Data",
    "text": "3.2 Data\nHere, we work with a network of African roads constructed by considering all continental cities with more than 100,000 inhabitants as the nodes, obtained from (Moriconi-Ebrard, Harre, and Heinrigs 2016). The edges of the network were created based on the road infrastructure from OpenStreetMap (“Openstreetmap.org”), using all primary roads, highways and trunk roads. Each edge was constructed by measuring the physical distance of consecutive points that describe the intricate patterns of the roads. Thus, a reasonably good estimate of its road length is available for each edge. Additional nodes besides cities are needed to fully describe the road infrastructure, such as some road intersections. These nodes are labelled as “transport nodes” and help define possible routes between cities. Some transport nodes correspond to towns with less than 100,000 inhabitants, so they are labelled as attached to nearby cities. The urban network enables us to consider the existing roads in the continent and measure the travelling distance rather than the physical distance between cities. The constructed network is formed by 7,361 nodes (2,162 cities and 5,199 transport nodes) and 9,159 edges. For more details on how the network was built, see (Prieto-Curiel et al. 2022).\nThe network is connected, meaning that it is possible to find a sequence of nodes and existing roads linking any pair of cities, and therefore, it is also possible to find the shortest road distance between any two cities and define it as the network distance. The network consists of 361,000 km of road infrastructure and connects 461 million people living in African cities, representing roughly 39% of the continent’s population (Prieto Curiel, Cabrera-Arnau, and Bishop 2022)."
  },
  {
    "objectID": "african-network.html#generating-networks-from-data-files",
    "href": "african-network.html#generating-networks-from-data-files",
    "title": "3  The African road network",
    "section": "3.2 Generating networks from data files",
    "text": "3.2 Generating networks from data files\n\n3.2.1 Preparing the data to generate an igraph object"
  },
  {
    "objectID": "african-network.html#creating-a-network-from-a-data-frame",
    "href": "african-network.html#creating-a-network-from-a-data-frame",
    "title": "3  The African road network",
    "section": "3.2 Creating a network from a data frame",
    "text": "3.2 Creating a network from a data frame\n\n#Support for simple features, a standardised way to encode spatial vector data\nlibrary(sf)\n#Data manipulation\nlibrary(dplyr)\n# An R package for network manipulation and analysis\nlibrary(igraph)\n# Provides a number of useful functions for working with character strings in R\nlibrary(stringr)\n\n\ndf_nodes &lt;- read.csv(\"https://raw.githubusercontent.com/rafaelprietocuriel/AfricanUrbanNetwork/main/AfricaNetworkNodes.csv\")\n\ndf_edges &lt;- read.csv(\"https://raw.githubusercontent.com/rafaelprietocuriel/AfricanUrbanNetwork/main/AfricaNetworkEdges.csv\")\n\n\ng_africa &lt;- graph_from_data_frame(d = df_edges,\n                                       vertices = df_nodes,\n                                       directed = FALSE)\n\n\nhead(V(g_africa)$name)\n\n[1] \"2320\" \"5199\" \"7098\" \"4220\" \"4858\" \"5331\"\n\n\n\nvertex_attr_names(g_africa)\n\n[1] \"name\"       \"agglosName\" \"x\"          \"y\"          \"Pop2015\"   \n[6] \"ISO3\"       \"Region\"     \"Between\"    \"degree\"    \n\n\n\nedge_attr_names(g_africa)\n\n[1] \"l\"       \"h\"       \"time\"    \"timeU\"   \"timeUCB\" \"border\" \n\n\n\n3.2.1 Visualising the African road network as a spatial network\n\nV(g_africa)$size &lt;- 0.3*(V(g_africa)$Pop2015/40000)^0.5\n\n\nplot(g_africa, vertex.size=V(g_africa)$size, edge.arrow.size=.15, edge.arrow.width=.2, edge.curved=0.1, edge.width=1, edge.color =\"gray90\",\nvertex.color=\"red\", vertex.frame.color=\"black\", vertex.frame.width=0.2,\nvertex.label=\" \", vertex.label.color=\"black\",\nvertex.label.cex=.65)"
  },
  {
    "objectID": "african-network.html#experiments",
    "href": "african-network.html#experiments",
    "title": "3  The African road network",
    "section": "3.3 Experiments",
    "text": "3.3 Experiments"
  },
  {
    "objectID": "african-network.html#network-metrics",
    "href": "african-network.html#network-metrics",
    "title": "3  The African road network",
    "section": "3.4 Network metrics",
    "text": "3.4 Network metrics\nThe following metrics can help us obtain further insights into the network structure. They are also valuable as a way to characterise the network so it can later be compared to other networks or to itself through time.\n\n3.4.1 Density\n\n# Calculate the edge density of the 'g_africa' graph\n# Edge density is the ratio of the number of edges to the number of possible edges\n# Loops (self-edges) are excluded from the calculation\nedge_density(g_africa, loops=FALSE)\n\n[1] 0.0003381142\n\n\nThe edge density is approximately 0.00034, giving as an indication that the network is quite sparse, since out of all possible edges, only 0.034% are present.\n\n\n3.4.2 Reciprocity\n\n# Calculate the reciprocity of the edges in the 'g_africa' graph\nreciprocity(g_africa)\n\n[1] 1\n\n\nThe reciprocity of this undirected network is naturally 1 by definition.\n\n\n3.4.3 Degree\nWe can compute the degree of each node with the function degree. In order to visualise the results, we produce a histogram\n\n# Compute degree of the nodes given by v belonging to graph g_africa\ndeg &lt;- degree(g_africa, v=V(g_africa))\n\n# Produces histogram of the frequency of nodes with a certain in-degree\nhist(deg, breaks = 50, main=\"Histogram of node degree\")\n\n\n\n\nWe observe that most nodes have degree 3. Nodes of degree 1 are terminal nodes. Nodes of degree 2 are relatively less common than those of degree 1 and 3. This is likely due to the method used to build the network, where all the transport nodes of degree 2 are eliminated in order to simplify the network. Beyond degree 4, it is relatively rare to find any nodes. From the histogram, we see the maximum degree observed in the network is 13. Below, we obtain the name of the node with the maximum degree as well as the value of the degree (13).\n\n# Retrieve the names of vertices in the 'g_africa' graph that have the highest degree\nV(g_africa)$agglosName[degree(g_africa) == max(degree(g_africa))]\n\n[1] \"Duduza Central\"\n\n# Retrieve the names of vertices (general names) in the 'g_africa' graph that have the highest degree\nhighest_degree_vertex_names &lt;- V(g_africa)$name[degree(g_africa) == max(degree(g_africa))]\n\n# Calculate the degree of vertices with the highest degree in the 'g_africa' graph\ndegree(g_africa, v=highest_degree_vertex_names)\n\n2896 \n  13 \n\n\n\n\n3.4.4 Distances\nWe can compute the shortest path between any pair of nodes, for example, between Cairo and Lagos. We store the output of the shortest path function in a dataframe called df_shortest_path.\n\n# Calculate the shortest paths between two specific vertices in the 'g_africa' graph\n# The source vertex is \"Cairo\" and the target vertex is \"Lagos\"\n# The length of the edges is used as weight in this calculation\n# Both path nodes and edges are included in the output\ndf_shortest_path &lt;- shortest_paths(g_africa,  from = V(g_africa)$agglosName==\"Cairo\", to = V(g_africa)$agglosName==\"Lagos\", predecessors=FALSE, weights=df_edges$l,  output = \"both\") \n\nIn this dataframe, the field “epath” stores the edges of the shortest path as a one-element list. We can extract the values of this list as the edge ids, which we then use to compute the total length of the shortest path between the two cities.\n\n# Retrieve the edge path indices from the first element of the 'epath' column in the 'df_shortest_path' data frame\nidx &lt;- df_shortest_path$epath[[1]]\n\n# Retrieve the lengths of edges along the path using the 'edge_attr' function and 'g_africa' graph\nlengths_epath &lt;- edge_attr(g_africa, \"l\", idx)\n\n# Calculate the sum of edge lengths along the path\nsum(lengths_epath)\n\n[1] 6084.359\n\n\nWe obtain that the shortest path is 6,084.359 km long. You can check for example on Google Maps what the distance by road is between the two cities. What do you obtain? What is the relative error between our estimation and the value from Google Maps?\nThe diameter of the African road network is the length of the longest shortest path between any pair of nodes:\n\ndiameter(g_africa, directed=TRUE, weights=NA)\n\n[1] 138\n\n\nAnd the mean distance computed over all the pairs of nodes is:\n\nmean_distance(g_africa, directed=TRUE, weights=NA)\n\n[1] 55.8602\n\n\n\n\n3.4.5 Centrality\nBelow we compute the closeness centrality using unweighted edges and represent the results in a histogram. The distribution looks bimodal. From the visualisation of the network that we obtained above, why do you think this is the case?\n\n# Calculate the closeness centrality for each vertex in the 'g_africa' graph, using unweighted edges (weights = NA)\nclose_centr &lt;- closeness(g_africa, weights = NA)\n\n# Create a histogram of closeness centrality values with 50 breaks and set the main title\nhist(close_centr, breaks = 50, main = \"Histogram of closeness centrality\")\n\n\n\n\nSimilarly, we also compute the betweenness centrality for all nodes and represent it as a histogram.\n\n# Calculate the betweenness centrality for each vertex in the 'g_africa' graph\nbetween_centr &lt;- betweenness(g_africa, v = V(g_africa), directed = TRUE, weights = NA)\n\n# Create a histogram of betweenness centrality values with 30 breaks and set the main title\nhist(between_centr, breaks = 30, main = \"Histogram of betweenness centrality\")\n\n\n\n\n\n\n3.4.6 Communities\nOne way of detecting communities in networks is by using modularity-based methods. Modularity measures the concentration of edges between groups of nodes compared to what we would expect if the edges were placed at random.\nAn example of a modularity-based method is the fast greedy algorithm (Newman 2004), which starts with the original network but with no edges, so there are as many communities as nodes. Then, in each iteration of the algorithm a randomly chosen edge from the original network is placed back. The selected quality measure, in this case modularity, is evaluated. The added edge is retained if it increases the value of the modularity, or discarded otherwise. The process is repeated until the modularity function is maximised.\nWe can test this algorithm for the African road network and plot the result to see how the nodes are assigned to different communities (note that a node can belong to more than one community):\n\n# Detect clusters using the fast greedy algorithm on the 'g_africa' graph\nclusters &lt;- cluster_fast_greedy(g_africa)\n\n# Create a plot of the 'g_africa' graph with specific visual attributes\nplot(g_africa, \n     vertex.size = V(g_africa)$size,          # Set vertex size based on the 'size' attribute\n     edge.arrow.size = 0.15,                 # Set arrow size for directed edges\n     edge.arrow.width = 0.2,                # Set arrow width for directed edges\n     edge.curved = 0.1,                     # Set edge curvature\n     edge.width = 1,                        # Set edge width\n     edge.color = \"gray90\",                 # Set edge color\n     vertex.color = membership(clusters),   # Set vertex color based on cluster membership\n     vertex.frame.color = \"black\",          # Set vertex frame (border) color\n     vertex.frame.width = 0.2,              # Set vertex frame (border) width\n     vertex.label = \" \",                    # Set vertex labels to empty\n     vertex.label.color = \"black\",          # Set vertex label color\n     vertex.label.cex = 0.65)               # Set vertex label size\n\n\n\n\nCan you find some interesting patterns in these communities?\n\n\n\n\n\nMoriconi-Ebrard, François, Dominique Harre, and Philipp Heinrigs. 2016. Urbanisation Dynamics in West Africa 1950–2010. https://doi.org/https://doi.org/https://doi.org/10.1787/9789264252233-en.\n\n\nNewman, M. E. J. 2004. “Fast Algorithm for Detecting Community Structure in Networks.” Phys. Rev. E 69 (June): 066133. https://doi.org/10.1103/PhysRevE.69.066133.\n\n\n“Openstreetmap.org.” https://www.openstreetmap.org/.\n\n\nPrieto Curiel, Rafael, Carmen Cabrera-Arnau, and Steven Richard Bishop. 2022. “Scaling Beyond Cities.” Frontiers in Physics 10. https://doi.org/10.3389/fphy.2022.858307.\n\n\nPrieto-Curiel, Rafael, Inhoi Heo, Abel Schumann, and Philipp Heinrigs. 2022. “Constructing a Simplified Interurban Road Network Based on Crowdsourced Geodata.” MethodsX 9: 101845. https://doi.org/https://doi.org/10.1016/j.mex.2022.101845."
  },
  {
    "objectID": "percolation.html#introduction",
    "href": "percolation.html#introduction",
    "title": "4  Percolation theory",
    "section": "4.2 Introduction",
    "text": "4.2 Introduction\nThe term percolation normally refers to the process whereby a fluid moves slowly through a porous material, for example, the percolation of rain water through rocks gives rise to aquifers. The study and modelling of this infiltration process in physics, chemistry and material science is known as percolation theory. If you think about it, a rock can be modelled as a three-dimensional lattice (if the rock was cube-shaped, this lattice would be like a Rubik cube but instead of being \\(3 \\times 3\\times 3\\), it is \\(n\\times n \\times n\\)). Then, the pores in the rock would be represented by “open sites” in this lattice (this would correspond to missing pieces in the Rubik cube) and the bits of the rock where there is material and therefore, no chance for the water to go through, would be represented by “closed sites” (this would correspond to pieces in the Rubik cube that are actually present). A typical question in percolation theory would then be as follows. If sites may be open with probability \\(p\\) or closed with probability \\(1-p\\) and these probabilities are assumed to be independent for each site, what is the probability that the water can go through the top to the bottom of the rock for a given value of \\(p\\)?\nIn recent decades, the mathematical study of percolation has been applied in a more general way, to understand the behavior of connected clusters or pathways in any system that can be modelled as a lattice or as a network. While the formulation of the percolation models varies slightly from lattices to networks, it follows the same principles. For example, let’s consider the spread of a certain pandemic, where contagion between two humans may take place with probability \\(p\\) if an infected individual spends more than 10 minutes at less than 2 meters away from a healthy one. Then, we can think of the pandemic as a fluid moving slowly, but instead of going through a porous rock, it goes through a social network of people. The people can be modelled as the nodes of the social network, and edges are present between two individuals if they spend long enough in close physical contact. Then, each edge or connection has an associated probability of contagion \\(p\\). Applying percolation theory, we could answer the question of “what are the chances that the pandemic makes its way from city A to city B given the structure of the network and the fact that the probability of contagion is \\(p\\)?”\nPercolation theory can therefore be used in a variety of contexts to better understand the properties of a system characterised by the connections between its components. Here, we use percolation models to improve our understanding of the structure and resilience of the African road network.\nAs before, we start by loading the data corresonding to the nodes and edges of the African road network:\n\n# Read edge and node data from URLs\ndf_edges &lt;- read.csv(\"https://raw.githubusercontent.com/rafaelprietocuriel/AfricanUrbanNetwork/main/AfricaNetworkEdges.csv\")\ndf_nodes &lt;- read.csv(\"https://raw.githubusercontent.com/rafaelprietocuriel/AfricanUrbanNetwork/main/AfricaNetworkNodes.csv\", encoding='UTF-8')\n\n\n# Filter the data frame df_nodes to only include rows where the 'Region' column is equal to \"South\"\ndf_nodes &lt;- subset(df_nodes, Region == \"South\")\n\n\n# Filter the data frame df_edges to only include rows where the 'from' column is in the list of Agglomeration_ID values from df_nodes\ndf_edges &lt;- subset(df_edges, from %in% df_nodes$Agglomeration_ID)\n\n# Filter the data frame df_edges to only include rows where the 'to' column is in the list of Agglomeration_ID values from df_nodes\ndf_edges &lt;- subset(df_edges, to %in% df_nodes$Agglomeration_ID)\n\nAnd we create an undirected graph from these data frames:\n\n# Create an undirected graph 'G' from a data frame 'df_edges' representing edges and a data frame 'df_nodes' representing vertices\nG &lt;- graph_from_data_frame(d = df_edges,\n                           vertices = df_nodes,\n                           directed = FALSE)\n\nAs before, we can visualise this network by running the code below\n\n# Assign a 'size' attribute to vertices in graph 'G' based on a function of population data\nV(G)$size &lt;- 0.5*(V(G)$Pop2015/10000)^0.4\n\n# Plot the graph 'G' with specific visual attributes\nplot(G, \n     vertex.size = V(G)$size,          # Set vertex size based on the 'size' attribute\n     edge.arrow.size = 0.15,           # Set arrow size for directed edges\n     edge.arrow.width = 0.2,          # Set arrow width for directed edges\n     edge.curved = 0.1,               # Set edge curvature\n     edge.width = 1,                  # Set edge width\n     edge.color = \"gray90\",           # Set edge color\n     vertex.color = \"red\",            # Set vertex color\n     vertex.frame.color = \"black\",    # Set vertex frame (border) color\n     vertex.frame.width = 0.2,        # Set vertex frame (border) width\n     vertex.label = \" \",              # Set vertex labels to empty\n     vertex.label.color = \"black\",    # Set vertex label color\n     vertex.label.cex = 0.65)         # Set vertex label size"
  },
  {
    "objectID": "percolation.html#uncovering-hierarchical-structures",
    "href": "percolation.html#uncovering-hierarchical-structures",
    "title": "4  Percolation theory",
    "section": "4.2 Uncovering hierarchical structures",
    "text": "4.2 Uncovering hierarchical structures"
  },
  {
    "objectID": "percolation.html#measuring-network-robustness",
    "href": "percolation.html#measuring-network-robustness",
    "title": "4  Percolation theory",
    "section": "4.4 Measuring network robustness",
    "text": "4.4 Measuring network robustness\n\n# Create an empty data frame to store component information\ncomponents &lt;- data.frame(nodeID = integer(0), component = integer(0), threshold = integer(0), gcc = integer(0))\n\n# Create empty lists to store thresholds, gccs, and ncs\nthresholds &lt;- list()\ngccs &lt;- list()\nncs &lt;- list()"
  },
  {
    "objectID": "percolation.html#uncovering-the-hierarchical-structure-of-the-african-road-network",
    "href": "percolation.html#uncovering-the-hierarchical-structure-of-the-african-road-network",
    "title": "4  Percolation theory",
    "section": "4.3 Uncovering the hierarchical structure of the African road network",
    "text": "4.3 Uncovering the hierarchical structure of the African road network\n\n# Read edge and node data from URLs\ndf_edges &lt;- read.csv(\"https://raw.githubusercontent.com/rafaelprietocuriel/AfricanUrbanNetwork/main/AfricaNetworkEdges.csv\")\ndf_nodes &lt;- read.csv(\"https://raw.githubusercontent.com/rafaelprietocuriel/AfricanUrbanNetwork/main/AfricaNetworkNodes.csv\", encoding='UTF-8')\n\n\n# Filter the data frame df_nodes to only include rows where the 'Region' column is equal to \"South\"\ndf_nodes &lt;- subset(df_nodes, Region == \"South\")\n\n\n# Filter the data frame df_edges to only include rows where the 'from' column is in the list of Agglomeration_ID values from df_nodes\ndf_edges &lt;- subset(df_edges, from %in% df_nodes$Agglomeration_ID)\n\n# Filter the data frame df_edges to only include rows where the 'to' column is in the list of Agglomeration_ID values from df_nodes\ndf_edges &lt;- subset(df_edges, to %in% df_nodes$Agglomeration_ID)\n\n\n# Create an undirected graph 'G' from a data frame 'df_edges' representing edges and a data frame 'df_nodes' representing vertices\nG &lt;- graph_from_data_frame(d = df_edges,\n                           vertices = df_nodes,\n                           directed = FALSE)\n\n\n# Assign a 'size' attribute to vertices in graph 'G' based on a function of population data\nV(G)$size &lt;- 0.5*(V(G)$Pop2015/10000)^0.4\n\n# Plot the graph 'G' with specific visual attributes\nplot(G, \n     vertex.size = V(G)$size,          # Set vertex size based on the 'size' attribute\n     edge.arrow.size = 0.15,           # Set arrow size for directed edges\n     edge.arrow.width = 0.2,          # Set arrow width for directed edges\n     edge.curved = 0.1,               # Set edge curvature\n     edge.width = 1,                  # Set edge width\n     edge.color = \"gray90\",           # Set edge color\n     vertex.color = \"red\",            # Set vertex color\n     vertex.frame.color = \"black\",    # Set vertex frame (border) color\n     vertex.frame.width = 0.2,        # Set vertex frame (border) width\n     vertex.label = \" \",              # Set vertex labels to empty\n     vertex.label.color = \"black\",    # Set vertex label color\n     vertex.label.cex = 0.65)         # Set vertex label size \n\n\n\n\n\n# Create an empty data frame to store component information\ncomponents &lt;- data.frame(nodeID = integer(0), component = integer(0), threshold = integer(0), gcc = integer(0))\n\n# Create empty lists to store thresholds, gccs, and ncs\nthresholds &lt;- list()\ngccs &lt;- list()\nncs &lt;- list()\n\n\n# Iterate over thresholds\nfor (i in seq(0, max(df_edges$l))) {\n  # Create a copy of the graph G\n  G_ &lt;- G \n  \n  # Find indices of edges with lengths greater than the current threshold (i)\n  edges_to_remove &lt;- which(E(G_)$l &gt; i)\n  \n  # Delete edges from G_ based on their indices\n  G_ &lt;- delete_edges(G_, edges_to_remove)\n  \n  # Get connected components of the modified graph G_\n  connected_components &lt;- components(G_)\n  \n  # Create a data frame 'df_threshold' containing node IDs, component indices,\n  # threshold values, and sizes of connected components\n  df_threshold &lt;- data.frame(nodeID = df_nodes$Agglomeration_ID, component = connected_components$membership, threshold = rep(i, times= nrow(df_nodes)), gcc = rep(max(connected_components$csize), times= nrow(df_nodes)))\n  \n  # Append 'df_threshold' to the 'components' data frame\n  components &lt;- rbind(components, df_threshold)\n  \n  # Append the current threshold value to the 'thresholds' list\n  thresholds &lt;- append(thresholds, i)\n  \n  # Append the maximum connected component size to the 'gccs' list\n  gccs &lt;- append(gccs, max(connected_components$csize))\n  \n  # Append the number of connected components to the 'ncs' list\n  ncs &lt;- append(ncs, connected_components$no)\n}\n\n# Display the first few rows of the 'components' data frame\nhead(components)\n\n     nodeID component threshold gcc\n4220   4220         1         0   1\n2333   2333         2         0   1\n2915   2915         3         0   1\n8177   8177         4         0   1\n7356   7356         5         0   1\n3165   3165         6         0   1\n\n\n\n# Plot the threshold values on the x-axis and the maximum connected component sizes (gccs) on the y-axis\nplot(thresholds, gccs)\n\n\n\n\n\n# Plot the threshold values on the x-axis and the number of connected components (ncs) on the y-axis\nplot(thresholds, ncs)"
  },
  {
    "objectID": "african-network.html#creating-a-network-from-data-frame",
    "href": "african-network.html#creating-a-network-from-data-frame",
    "title": "3  The African road network",
    "section": "3.3 Creating a network from data frame",
    "text": "3.3 Creating a network from data frame\nThe data that specifies the nodes and edges of the African road network is stored in two csv files, one for nodes and one for edges. This data can be loaded in two dataframes:\n\n# Read the CSV file containing network nodes data from a URL\ndf_nodes &lt;- read.csv(\"https://raw.githubusercontent.com/rafaelprietocuriel/AfricanUrbanNetwork/main/AfricaNetworkNodes.csv\")\n\n# Read the CSV file containing network edges data from a URL\ndf_edges &lt;- read.csv(\"https://raw.githubusercontent.com/rafaelprietocuriel/AfricanUrbanNetwork/main/AfricaNetworkEdges.csv\")\n\nWe can then create an undirected graph as an igraph object from the data frames corresponding to the nodes and edges:\n\n# Create a graph 'g_africa' from data frames 'df_edges' and 'df_nodes'\n# The graph is undirected (directed = FALSE)\ng_africa &lt;- graph_from_data_frame(d = df_edges,\n                                       vertices = df_nodes,\n                                       directed = FALSE)\n\nWe can have a look at the names of the vertex attributes, which are automatically taken from the columns in the df_nodes data frame:\n\n# Retrieve the attribute names associated with vertices in the 'g_africa' graph\nvertex_attr_names(g_africa)\n\n[1] \"name\"       \"agglosName\" \"x\"          \"y\"          \"Pop2015\"   \n[6] \"ISO3\"       \"Region\"     \"Between\"    \"degree\"    \n\n\nwhere “name” is the ID of each node in the network, “agglosName” is the name of the city represented by the node, it is set to “road” if the node is a transport node. “x” and “y” represent the coordinates of each node, “Pop2015” is the population of the city nodes, “ISO3” is the code for the country that each node is situated in, “Region” represents the region within the African continent that each node is situated in, and “Between” and “degree” represent the betweenness centrality and the degree of each node in the network, which we will also compute below.\nIn particular, we can look at the first few values of the attribute “name”:\n\n# Retrieve the first few vertex names from the 'g_africa' graph\nhead(V(g_africa)$name)\n\n[1] \"2320\" \"5199\" \"7098\" \"4220\" \"4858\" \"5331\"\n\n\nWe can also obtain the names of the edge attributes, which are taken from the columns in the df_edges data frame:\n\n# Retrieve the attribute names associated with edges in the 'g_africa' graph\nedge_attr_names(g_africa)\n\n[1] \"l\"       \"h\"       \"time\"    \"timeU\"   \"timeUCB\" \"border\" \n\n\nwhere “l” represents the length in kilometres by road segment and it considers curves, “h” is the type of edge (primary, highway, etc.), “time” is the estimated minutes to travel through the edge, considering different speeds for distinc types of road, “timeU” is also the estimated minutes to travel throgh the edge, but allowing extra time if the extrema of the edge are urban nodes, “timeUCB” allows extra time for edges that cross a border, “border” is a binary variable taking value 1 is it crosses a border and 0 otherwise and “added” is also a binary variable taking value 1 if an edge was artificially added to ensure the connectedness of the network and 0 otherwise.\n\n3.3.1 Visualising the African road network as a spatial network\nWhat does the African road network that we just built look like? We can find out very easily using the plot function. But in order to achieve a nice-looking graph, we need to play a bit with the values of the arguments of this function. For example, we will plot the size of the nodes according to the population of the cities that they represent. But some cities are orders of magnitude larger than others, which would relut in some gigantic nodes for a few cities and tiny ones for the majority. In order to weaken this effect, we first apply a scaling function that redefines the size of the nodes:\n\n# Calculate and assign a 'size' attribute to vertices in the 'g_africa' graph\n# The size is determined based on the population data ('Pop2015') of each vertex\nV(g_africa)$size &lt;- 0.3*(V(g_africa)$Pop2015/40000)^0.5\n\nNow we are ready to plot the network, with a few extra modifications to the default plot in order to improve the appearance. As an exercise, you may want to try to plot the default visualisation by simply running plot(g_africa). If you do this, you will understand better why it is worth it spending some time playing with the values of the parameters in the plot function.\n\nplot(g_africa, vertex.size=V(g_africa)$size, edge.arrow.size=.15, edge.arrow.width=.2, edge.curved=0.1, edge.width=1, edge.color =\"gray90\",\nvertex.color=\"red\", vertex.frame.color=\"black\", vertex.frame.width=0.2,\nvertex.label=\" \", vertex.label.color=\"black\",\nvertex.label.cex=.65)"
  },
  {
    "objectID": "percolation.html#dependencies",
    "href": "percolation.html#dependencies",
    "title": "4  Percolation theory",
    "section": "4.1 Dependencies",
    "text": "4.1 Dependencies\n\n# Load required packages\nlibrary(igraph)    # for network analysis\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\nlibrary(ggplot2)\nlibrary(ggraph)\nlibrary(patchwork)\nlibrary(tidygraph)\n\n\nAttaching package: 'tidygraph'\n\n\nThe following object is masked from 'package:igraph':\n\n    groups\n\n\nThe following object is masked from 'package:stats':\n\n    filter"
  },
  {
    "objectID": "percolation.html#modelling-community-formation-in-the-african-road-network",
    "href": "percolation.html#modelling-community-formation-in-the-african-road-network",
    "title": "4  Percolation theory",
    "section": "4.3 Modelling community formation in the African road network",
    "text": "4.3 Modelling community formation in the African road network\nAt the end of the previous session, we used the fast greedy algorithm to detect communities based on the topology of the African road network. We used an R implementation of the fast greedy algorithm through the built-in function cluter_fast_greedy(). While a built-in function gives us results in a very straightforward way, it also makes the process less transparent. In this section, we implement a percolation theory approach to model the formation of communities of nodes (cities) as the connectivity properties of the network are varied.\n\n# Iterate over thresholds\nfor (j in seq(30, 90, 45)) {\n\n  df_edges_perco &lt;- subset(df_edges, timeUCB &lt; j)\n  \n  G_perco &lt;- graph_from_data_frame(d = df_edges_perco,\n                           vertices = df_nodes,\n                           directed = FALSE)\n  \n  # Find connected components\n  component_info &lt;- components(G_perco)\n\n  # Extract component membership\n  component_membership &lt;- component_info$membership\n\n  # Create a color palette for components\n  num_components &lt;- max(component_membership)\n  colors &lt;- rainbow(num_components)\n  \n  # Assign a 'size' attribute to vertices in graph 'G' based on a function of population data\n  V(G_perco)$size &lt;- 0.5*(V(G_perco)$Pop2015/10000)^0.4\n\n  G_perco_tbl &lt;- as_tbl_graph(G_perco)\n  \n  # Plot the graph 'G_' with specific visual attributes\n  plot_threshold &lt;- ggraph(G_perco_tbl) +\n    geom_edge_link(aes(edge_alpha = 0.5)) +\n    geom_node_point(aes(color = colors[component_membership]), \n                    size = V(G_perco)$size) +\n    theme_void()\n    \n     # plot(G_perco, \n     # vertex.size = V(G_perco)$size,         # Set vertex size based on the 'size' attribute\n     # edge.arrow.size = 0.15,          # Set arrow size for directed edges\n     # edge.arrow.width = 0.2,          # Set arrow width for directed edges\n     # edge.curved = 0.1,               # Set edge curvature\n     # edge.width = 1,                  # Set edge width\n     # edge.color = \"gray90\",           # Set edge color\n     # vertex.color = colors[component_membership],            # Set vertex color\n     # vertex.frame.color = \"black\",    # Set vertex frame (border) color\n     # vertex.frame.width = 0.2,        # Set vertex frame (border) width\n     # vertex.label = \" \",              # Set vertex labels to empty\n     # vertex.label.color = \"black\",    # Set vertex label color\n     # vertex.label.cex = 0.65)         # Set vertex label size \n  \n  # Generate the variable name dynamically\n  variable_name &lt;- paste(\"plot_\", j, sep = \"\")\n  \n  # Assign a value to the dynamically named variable\n  assign(variable_name, plot_threshold)  # Replace with your variable assignment\n  \n}\n\nUsing \"stress\" as default layout\n\n\nWarning: Existing variables `x` and `y` overwritten by layout variables\n\n\nUsing \"stress\" as default layout\n\n\nWarning: Existing variables `x` and `y` overwritten by layout variables\n\n\n\nplot_30 + plot_75\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead."
  },
  {
    "objectID": "percolation.html#original-by-removing",
    "href": "percolation.html#original-by-removing",
    "title": "4  Percolation theory",
    "section": "4.5 Original by removing",
    "text": "4.5 Original by removing\n\n# Iterate over thresholds\nfor (i in seq(0, max(df_edges$l))) {\n  # Create a copy of the graph G\n  G_ &lt;- G \n  \n  # Find indices of edges with lengths greater than the current threshold (i)\n  edges_to_remove &lt;- which(E(G_)$l &gt; i)\n  \n  # Delete edges from G_ based on their indices\n  G_ &lt;- delete_edges(G_, edges_to_remove)\n  \n  # Get connected components of the modified graph G_\n  connected_components &lt;- components(G_)\n  \n  # Create a data frame 'df_threshold' containing node IDs, component indices,\n  # threshold values, and sizes of connected components\n  df_threshold &lt;- data.frame(nodeID = df_nodes$Agglomeration_ID, component = connected_components$membership, threshold = rep(i, times= nrow(df_nodes)), gcc = rep(max(connected_components$csize), times= nrow(df_nodes)))\n  \n  # Append 'df_threshold' to the 'components' data frame\n  components &lt;- rbind(components, df_threshold)\n  \n  # Append the current threshold value to the 'thresholds' list\n  thresholds &lt;- append(thresholds, i)\n  \n  # Append the maximum connected component size to the 'gccs' list\n  gccs &lt;- append(gccs, max(connected_components$csize))\n  \n  # Append the number of connected components to the 'ncs' list\n  ncs &lt;- append(ncs, connected_components$no)\n}\n\n# Display the first few rows of the 'components' data frame\nhead(components)\n\n     nodeID component threshold gcc\n4220   4220         1         0   1\n2333   2333         2         0   1\n2915   2915         3         0   1\n8177   8177         4         0   1\n7356   7356         5         0   1\n3165   3165         6         0   1\n\n\n\n# Plot the threshold values on the x-axis and the maximum connected component sizes (gccs) on the y-axis\nplot(thresholds, gccs)\n\n\n\n\n\n# Plot the threshold values on the x-axis and the number of connected components (ncs) on the y-axis\nplot(thresholds, ncs)"
  },
  {
    "objectID": "african-network.html#dependencies",
    "href": "african-network.html#dependencies",
    "title": "3  The African road network",
    "section": "3.1 Dependencies",
    "text": "3.1 Dependencies\n\n# An R package for network manipulation and analysis\nlibrary(igraph)"
  }
]